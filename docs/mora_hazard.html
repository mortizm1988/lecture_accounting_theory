<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.4.552">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Marcelo Ortiz, Universitat Pompeu Fabra">
<meta name="dcterms.date" content="2024-09-01">

<title>Optimal Compensation and Accounting</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script>window.backupDefine = window.define; window.define = undefined;</script><script src="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.js"></script>
  <script>document.addEventListener("DOMContentLoaded", function () {
 var mathElements = document.getElementsByClassName("math");
 var macros = [];
 for (var i = 0; i < mathElements.length; i++) {
  var texText = mathElements[i].firstChild;
  if (mathElements[i].tagName == "SPAN") {
   katex.render(texText.data, mathElements[i], {
    displayMode: mathElements[i].classList.contains('display'),
    throwOnError: false,
    macros: macros,
    fleqn: false
   });
}}});
  </script>
  <script>window.define = window.backupDefine; window.backupDefine = undefined;</script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.css">

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="floating">

<div id="quarto-search-results"></div>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <nav id="TOC" role="doc-toc" class="toc-active" data-toc-expanded="99">
    <h2 id="toc-title">On this page</h2>
   
  <ul class="collapse">
  <li><a href="#introduction-to-moral-hazard" id="toc-introduction-to-moral-hazard" class="nav-link active" data-scroll-target="#introduction-to-moral-hazard"><span class="header-section-number">1</span> Introduction to Moral Hazard</a></li>
  <li><a href="#general-model-of-moral-hazard" id="toc-general-model-of-moral-hazard" class="nav-link" data-scroll-target="#general-model-of-moral-hazard"><span class="header-section-number">2</span> General Model of Moral Hazard</a>
  <ul class="collapse">
  <li><a href="#agents-problem" id="toc-agents-problem" class="nav-link" data-scroll-target="#agents-problem"><span class="header-section-number">2.1</span> Agent’s Problem</a></li>
  <li><a href="#principals-problem" id="toc-principals-problem" class="nav-link" data-scroll-target="#principals-problem"><span class="header-section-number">2.2</span> Principal’s Problem</a></li>
  <li><a href="#first-order-simplification" id="toc-first-order-simplification" class="nav-link" data-scroll-target="#first-order-simplification"><span class="header-section-number">2.3</span> First-order Simplification</a></li>
  <li><a href="#optimal-compensation-terms" id="toc-optimal-compensation-terms" class="nav-link" data-scroll-target="#optimal-compensation-terms"><span class="header-section-number">2.4</span> Optimal Compensation Terms</a></li>
  <li><a href="#sec-general_measures" id="toc-sec-general_measures" class="nav-link" data-scroll-target="#sec-general_measures"><span class="header-section-number">2.5</span> Accounting performance measures</a></li>
  </ul></li>
  <li><a href="#linear-exponential-normal-len-moral-hazard-models" id="toc-linear-exponential-normal-len-moral-hazard-models" class="nav-link" data-scroll-target="#linear-exponential-normal-len-moral-hazard-models"><span class="header-section-number">3</span> Linear-Exponential-Normal (LEN) Moral Hazard Models</a>
  <ul class="collapse">
  <li><a href="#agents-problem-1" id="toc-agents-problem-1" class="nav-link" data-scroll-target="#agents-problem-1"><span class="header-section-number">3.1</span> Agent’s Problem</a></li>
  <li><a href="#principals-problem-1" id="toc-principals-problem-1" class="nav-link" data-scroll-target="#principals-problem-1"><span class="header-section-number">3.2</span> Principal’s Problem</a></li>
  <li><a href="#optimal-compensation-terms-1" id="toc-optimal-compensation-terms-1" class="nav-link" data-scroll-target="#optimal-compensation-terms-1"><span class="header-section-number">3.3</span> Optimal Compensation Terms</a></li>
  <li><a href="#accounting-perfomance-measures" id="toc-accounting-perfomance-measures" class="nav-link" data-scroll-target="#accounting-perfomance-measures"><span class="header-section-number">3.4</span> Accounting Perfomance Measures</a></li>
  <li><a href="#optimal-contract-with-additional-performance-measures" id="toc-optimal-contract-with-additional-performance-measures" class="nav-link" data-scroll-target="#optimal-contract-with-additional-performance-measures"><span class="header-section-number">3.5</span> Optimal Contract with additional Performance Measures</a></li>
  <li><a href="#suggestions-for-further-reading" id="toc-suggestions-for-further-reading" class="nav-link" data-scroll-target="#suggestions-for-further-reading"><span class="header-section-number">3.6</span> Suggestions for Further Reading</a></li>
  </ul></li>
  </ul>
</nav>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Optimal Compensation and Accounting</h1>
</div>



<div class="quarto-title-meta">

    <div>
    <div class="quarto-title-meta-heading">Author</div>
    <div class="quarto-title-meta-contents">
             <p>Marcelo Ortiz, Universitat Pompeu Fabra </p>
          </div>
  </div>
    
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">September 1, 2024</p>
    </div>
  </div>
  
    
  </div>
  


</header>


<section id="introduction-to-moral-hazard" class="level1" data-number="1">
<h1 data-number="1"><span class="header-section-number">1</span> Introduction to Moral Hazard</h1>
<p>Moral hazard arises when one party in a transaction can take actions that affect the value of the transaction for the other party. However, those actions are either unobservable or only imperfectly inferable by the affected party. This problem typically occurs in situations where two conditions are present: <strong>hidden action</strong> and <strong>risk aversion</strong>.</p>
<ol type="1">
<li><p><strong>Hidden action</strong>: Refers to actions taken by one party that cannot be directly monitored or measured by the other party. As a result, the affected party cannot perfectly determine whether adverse outcomes are due to poor performance, lack of effort, or external factors.</p></li>
<li><p><strong>Risk aversion</strong>: At least one of the parties involved must prefer avoiding risk. They value stability and predictability, often making them cautious about transactions or agreements that expose them to unpredictable outcomes.</p></li>
</ol>
<p>The moral hazard problem is fundamentally about the misalignment of incentives between parties. Specifically, the party whose actions are unobservable might not have adequate incentives to act in the best interest of the other party.</p>
<p>Solving Moral hazard conflicts implies solving two challenges:</p>
<ol type="1">
<li><strong>Provision of adequate incentives</strong>: Designing mechanisms to motivate the party taking the hidden action to behave in a way that aligns with the other party’s goals.</li>
<li><strong>Efficient risk distribution</strong>: Finding a balance in how risk is shared between the parties, so that each party bears the appropriate level of risk without undermining incentives.</li>
</ol>
<p>These two objectives often conflict. There is a substitution effect: when one party is overly shielded from risk, they may lack the incentive to take efficient actions that benefit the other party. As a result, designing an optimal compensation or incentive scheme requires balancing risk-sharing with providing the right incentives.</p>
<p>The focus of this class will be moral hazard conflicts arising within a firm, typically between a shareholder (the pricipal) and a manager (the agent). The principal aims to hire the agent for running a risky project, and offers the agent a contract which stablishes the agent’s compensation conditional on the outcome of the risky project. The agent first decides whether to accept the contract and then how much effort put into managing the project. The principal requires informations to infer the value of the project’s outcome and the agent’s effort to be able to compute the agent’s compensation and its own net profits.</p>
<p>In this setting, accounting is naturally embedded into moral hazard problems. <strong>Accounting information</strong> must have several key characteristics to be useful for decision-making. Accounting information must be relevant, comparable, verifiable, and timeliness. Scholars have studied how these characteristics can be used to design optimal contracts that mitigate moral hazard problems.</p>
<p>This reading note starts by developing a simple example of a moral hazard problem to illustrate the nature of the problem and the trade-offs involved in solving it. We then move on to a more general moral hazard model, allowing us to add further features to the model. We will also discuss how accounting systems must generate <strong>performance measures</strong>, and how these measures can be used to design optimal contracts. Then, we discuss the role of comparability for <strong>relative performance evaluation</strong> and the role of disclosure of <strong>verifiable</strong> private information in the context of moral hazard. Lastly, we will discuss how the <strong>timeliness</strong> of accounting information can be used to design dynamic incentive contracts.</p>
<section id="a-very-simple-example" class="level3" data-number="1.0.1">
<h3 data-number="1.0.1" class="anchored" data-anchor-id="a-very-simple-example"><span class="header-section-number">1.0.1</span> A very simple example</h3>
<p>Let’s assume that a company (principal) hires a manager (agent) responsible for running the business. The company’s outcomes depend on both random factors and the manager’s effort. For now, let’s assume the effort can be either high (A) or low (B), and the company’s outcomes can either be success (E) or failure (F). The company’s profit in the success scenario is $360, and in the failure scenario, it is $200. The probability of success is 75% with high effort and 25% with low effort.</p>
<p>Therefore, the expected profit of the principal when effort is high is: <span class="math inline">360 \times 0.75 + 200 \times 0.25 = 320</span>. In contrast, when the effort is low the expected profit is: <span class="math inline">360 \times 0.25 + 200 \times 0.75 = 240</span>.</p>
<p>This can be summarized in the following table:</p>
<table class="table">
<thead>
<tr class="header">
<th></th>
<th>High Effort (A)</th>
<th>Low Effort (B)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Success (S)</td>
<td>75%</td>
<td>25%</td>
</tr>
<tr class="even">
<td>Failure (F)</td>
<td>25%</td>
<td>75%</td>
</tr>
<tr class="odd">
<td>Expected Profit</td>
<td>$320</td>
<td>$240</td>
</tr>
</tbody>
</table>
<p>We assume that the principal seeks to maximize the expected value of their net profits (expected value minus the payment to the agent). For now, let’s consider the principal to be risk-neutral.</p>
<p>The agent (manager) aims to maximize an expected utility function of the form:</p>
<p><span class="math display">
U = U(w) - v(e)
</span></p>
<p>Where <span class="math inline">U(w)</span> is the utility of the payment received (remuneration), and <span class="math inline">v(e)</span> is the cost of effort <span class="math inline">e</span>.</p>
<p>We can distinguish four possible cases:</p>
<ol type="1">
<li>Observable effort, risk-neutral agent</li>
<li>Non-observable effort, risk-neutral agent</li>
<li>Observable effort, risk-averse agent</li>
<li>Non-observable effort, risk-averse agent</li>
</ol>
</section>
<section id="observable-effort-risk-neutral-agent" class="level3" data-number="1.0.2">
<h3 data-number="1.0.2" class="anchored" data-anchor-id="observable-effort-risk-neutral-agent"><span class="header-section-number">1.0.2</span> Observable Effort, Risk-Neutral Agent</h3>
<p>Let’s assume an agent with a utility function <span class="math inline">U = w - v(e)</span>, and a reservation utility of <span class="math inline">\underline{U} = 81</span>. The costs of effort are <span class="math inline">v(B) = 0</span> and <span class="math inline">v(A) = 63</span>. (The numbers are arbitrary and chosen to facilitate later comparisons).</p>
<p>If the principal settles for low effort, they offer the agent a salary equal to the reservation utility <span class="math inline">w = 81</span>. The expected profit for the principal is 240, and the net benefit is <span class="math inline">240 - 81 = 159</span>.</p>
<p>If the principal wants to ensure high effort, the agent’s remuneration must cover the disutility of effort, i.e., <span class="math inline">w = 81 + 63 = 144</span>. The net profit for the principal in this case is <span class="math inline">320 - 144 = 176</span>.</p>
<p>Thus, for the principal, the best alternative is to offer a fixed payment of 144 and obtain an expected profit of 176.</p>
</section>
<section id="non-observable-effort-risk-neutral-agent" class="level3" data-number="1.0.3">
<h3 data-number="1.0.3" class="anchored" data-anchor-id="non-observable-effort-risk-neutral-agent"><span class="header-section-number">1.0.3</span> Non-Observable Effort, Risk-Neutral Agent</h3>
<p>Now, consider the case where the effort (A or B) is non-observable and the agent continue being risk-neutral. In this case, the conflict between incentives and risk distribution is easily resolved. The most effective way to provide incentives is to make the agent bear all the consequences of their decisions.</p>
<p>The contract cannot depend on effort because effort is neither observable nor verifiable. However, results such as profits are observable. Therefore, the principal can exploit the correlation between effort and profits to incentivize the agent. The principal will pay <span class="math inline">X</span> in case of success ($E$), and <span class="math inline">Y</span> in case of failure (<span class="math inline">F</span>). This introduces uncertainty for the agent.</p>
<p>The principal can induce high effort by offering the agent a contract characterized by a compensation conditional on the outcome: <span class="math inline">W_E</span> and <span class="math inline">W_F</span>, with the following requirements:</p>
<ol type="1">
<li><strong>Individual Rationality</strong>: The utility for the agent must be greater than their reservation utility.</li>
<li><strong>Incentive Compatibility</strong>: The utility of exerting high effort must be greater than the utility of low effort, i.e.,<span class="math inline">E[U(A)] &gt; E[U(B)]</span>.</li>
</ol>
<p>In our example, the constraints are:</p>
<p><span class="math display">
0.75 W_E + 0.25 W_F - 63 \geq 81
</span> <span class="math display">
0.75 W_E + 0.25 W_F - 63 \geq 0.25 W_E + 0.75 W_F
</span></p>
<p>As it is inefficient for the principal to pay more than needed to influence effort, the previous system of inequations are solved at the equality conditions. The optimal contract in this case involves:</p>
<p><span class="math display">
W_E = 184, \quad W_F = 24.
</span></p>
</section>
<section id="observable-effort-risk-averse-agent" class="level3" data-number="1.0.4">
<h3 data-number="1.0.4" class="anchored" data-anchor-id="observable-effort-risk-averse-agent"><span class="header-section-number">1.0.4</span> Observable Effort, Risk-Averse Agent</h3>
<p>Qhat happens when we have a risk-averse agent? For example, assume the utility function <span class="math inline">U = W^{1/2} - v(e)</span>, where <span class="math inline">v(A) = 3</span> and <span class="math inline">v(B) = 0</span>, and the reservation utility is <span class="math inline">\underline{U} = 9</span>.</p>
<p>To induce low effort, it is sufficient to offer a fixed salary that yields a utility level equal to or greater than the reservation utility (<span class="math inline">W=\underline{U}^2=81</span>). The principal’s expected net profit is <span class="math inline">240 - 81 = 159</span>, the same as in the scenario with a risk-neutral agent.</p>
<p>To induce high effort, the agent needs to be compensated for the additional disutility of the high effort. As effort can be observed, this can be achieved with a fixed salary of <span class="math inline">144=(\underline{U}+3)^2</span>, conditioned on high effort . Thus, the expected net profit for the principal is <span class="math inline">320 - 144 = 176</span>, higher than the profit for low effort (though it may not always be optimal to pay for high effort).</p>
<p>In this case, the agent’s risk aversion does not pose a problem since there is no uncertainty involved. The agent’s action and payment are not contingent on the state of nature.<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a></p>
</section>
<section id="non-observable-effort-and-risk-averse-agent" class="level3" data-number="1.0.5">
<h3 data-number="1.0.5" class="anchored" data-anchor-id="non-observable-effort-and-risk-averse-agent"><span class="header-section-number">1.0.5</span> Non-Observable Effort and Risk-Averse Agent</h3>
<p>The lack of observability of effort forces to create the compensation contract contingent on outcomes (which are correlated with effort) or abandoning variable compensation altogether. In this scenario we can see the main conflict in moral hazard problems:</p>
<ul>
<li><p><strong>Efficient Risk Distribution</strong>: the risk-neutral party (the principal) should bear all the risk, while the risk-averse party (the agent) remains on the certainty line.</p></li>
<li><p><strong>Incentive Problem</strong>: For proper incentives, the agent must perceive differences in remuneration based on their effort level.</p></li>
</ul>
<p>The challenge is to find the optimal balance between incentive provision and risk distribution. In the case of a risk-neutral agent, this was not a significant issue, as simply transferring residual control to the agent solved the problem. However, in this case, any variable compensation scheme must compensate the risk-averse agent for the risk they bear.</p>
<p>For comparison, let’s keep the utility function and parameters from the previous section. If the principal desires low effort, a fixed salary of <span class="math inline">81</span> is sufficient. However, to incentive high effort, the contract with <span class="math inline">w = 144</span> will no longer suffice because effort is not observable, and uniform wages provide an incentive to cheat by exerting low effort.</p>
<p>The contract that induces high effort must meet both the individual rationality and incentive compatibility constraints, expressed as:</p>
<p><span class="math display">
0.75U(W_E) + 0.25U(W_F) - 3 \geq 9
</span></p>
<p><span class="math display">
0.75U(W_E) + 0.25U(W_F) - 3 \geq 0.25U(W_E) + 0.75U(W_F)
</span></p>
<p>The second constraint can be written as <span class="math inline">0.5[U(W_E) - U(W_F)] \geq 3</span>. This captures the difference in utilities associated with the remuneration in each state, ensuring that high effort is chosen over low effort. The solution for this system of equation is <span class="math inline">W_E = 182.25</span> and <span class="math inline">W_F = 56.25</span>. The expected cost of the contract that incentives high effor for the principal is <span class="math inline">0.75 \times 182.25 + 0.25 \times 56.25 = 159.75</span>, leaving them with an expected net benefit of <span class="math inline">320 - 159.75 = 169.25</span>.</p>
<p>It is important to note that inducing high effort now has a higher cost for the principal compared to the observable effort case. The cost has increased from <span class="math inline">144</span> to <span class="math inline">159.75</span>. The additional <span class="math inline">6.75</span> is the cost of non-observability, which economically corresponds to compensating the agent for the risk assumed.</p>
</section>
</section>
<section id="general-model-of-moral-hazard" class="level1" data-number="2">
<h1 data-number="2"><span class="header-section-number">2</span> General Model of Moral Hazard</h1>
<p>This section borrows from <span class="citation" data-cites="Lambert_2001">Lambert (<a href="#ref-Lambert_2001" role="doc-biblioref">2001</a>)</span> Section 2 and <span class="citation" data-cites="Bolton_Dewatripont_2005">Bolton and Dewatripont (<a href="#ref-Bolton_Dewatripont_2005" role="doc-biblioref">2005</a>)</span> Chapter 4. We present a general version of the moral hazard problem, starting with the basic framework and then applying specific functional forms for effort and performance outcomes.</p>
<p>Moral hazard problems can be modeled as <strong>sequential games</strong>. In the first stage, the principal offers a contract. In the second stage, the agent decides whether to accept or reject the contract, and if accepted, chooses their level of effort. The game is solved using <strong>backward induction</strong>, where the agent’s optimal actions are determined first, and the principal designs the contract anticipating those actions.</p>
<p>Both the principal and the agent are assumed to have full knowledge of the game’s structure, including their respective preferences and available options. They also observe the outcome and share identical beliefs about the probability distribution governing the outcome.</p>
<section id="agents-problem" class="level2" data-number="2.1">
<h2 data-number="2.1" class="anchored" data-anchor-id="agents-problem"><span class="header-section-number">2.1</span> Agent’s Problem</h2>
<p>In the final stage of the game, the agent selects an effort level <span class="math inline">e</span>, affecting the probability distribution of <span class="math inline">n</span> possible outcomes <span class="math inline">x_i</span>. Let <span class="math inline">p_i(e)</span> denote the probability of outcome <span class="math inline">x_i</span> given effort <span class="math inline">e</span>. The agent’s utility function is defined as <span class="math inline">U(w(x_i)) - v(e)</span>, where <span class="math inline">U(w(x_i))</span> is the utility derived from compensation <span class="math inline">w(x_i)</span> for outcome <span class="math inline">x_i</span>, and <span class="math inline">v(e)</span> represents the disutility (cost) of effort.</p>
<p>The agent maximizes expected utility by choosing the effort level <span class="math inline">e</span> that satisfies:</p>
<p><span class="math display">
e \in \arg\max \sum_{i=1}^n p_i(e)U(w(x_i)) - v(e)
</span></p>
<p>This defines the <strong>incentive compatibility constraint</strong> (ICC), which ensures the agent has an incentive to choose the desired effort level.</p>
<p>Before exerting effort, the agent decides whether to participate by comparing the expected utility of the contract with their reservation utility <span class="math inline">\underline{U}</span> (outside option):</p>
<p><span class="math display">
\sum_{i=1}^n p_i(e)U(w(x_i)) - v(e) \geq \underline{U}
</span></p>
<p>This is the <strong>participation constraint</strong> (PC), which ensures that the agent prefers the contract over their outside option.</p>
</section>
<section id="principals-problem" class="level2" data-number="2.2">
<h2 data-number="2.2" class="anchored" data-anchor-id="principals-problem"><span class="header-section-number">2.2</span> Principal’s Problem</h2>
<p>In the first stage, the principal designs the contract, taking into account the agent’s optimal behavior (effort choice). The principal maximizes their expected benefit <span class="math inline">B(x_i - w(x_i))</span>, which is the difference between the outcome <span class="math inline">x_i</span> and the agent’s compensation <span class="math inline">w(x_i)</span>. The principal’s problem can be written as:</p>
<p><span id="eq-agent_problem"><span class="math display">
\begin{aligned}
    \max_{w(x_i), e} \quad &amp; \sum_{i=1}^n p_i(e)[B(x_i - w(x_i))] &amp;  \\
    \text{subject to:} \quad &amp; \underline{U} \leq \sum_{i=1}^n p_i(e) U(w(x_i)) - v(e) &amp; \quad  \text{(PC)} \\
    &amp; e \in \arg\max \left\{ \sum_{i=1}^n p_i(e) U(w(x_i)) - v(e) \right\} &amp; \quad  \text{(ICC)}
\end{aligned}
\tag{1}</span></span></p>
</section>
<section id="first-order-simplification" class="level2" data-number="2.3">
<h2 data-number="2.3" class="anchored" data-anchor-id="first-order-simplification"><span class="header-section-number">2.3</span> First-order Simplification</h2>
<p>Solving the ICC in <a href="#eq-agent_problem" class="quarto-xref">Equation&nbsp;1</a> can be complex. However, under certain conditions, the agent’s optimal effort can be determined by the <strong>first-order condition</strong>. Assuming the agent’s optimal effort is interior, the first-order condition is:</p>
<p><span class="math display">
\sum_{i=1}^n p_i'(e)U(w(x_i)) - v'(e) = 0
</span></p>
<p>This simplification is often used because it avoids solving the double maximization problem in <a href="#eq-agent_problem" class="quarto-xref">Equation&nbsp;1</a>. However, the first-order condition is <strong>necessary but not sufficient</strong>. Since effort influences both disutility <span class="math inline">v(e)</span> and the outcome probabilities <span class="math inline">p_i(e)</span>, the expected utility function may not be concave, meaning additional solutions (including suboptimal ones) could arise.</p>
</section>
<section id="optimal-compensation-terms" class="level2" data-number="2.4">
<h2 data-number="2.4" class="anchored" data-anchor-id="optimal-compensation-terms"><span class="header-section-number">2.4</span> Optimal Compensation Terms</h2>
<p>Using the first-order condition approach, we can formulate the Lagrangian for the principal’s problem as:</p>
<p><span class="math display">
L(w(x_i),e) = \sum_{i=1}^n p_i(e)[B(x_i - w(x_i))] + \lambda \left[ \sum_{i=1}^n p_i(e) U(w(x_i)) - v(e) - \underline{U} \right] + \mu \left[ \sum_{i=1}^n p_i'(e)U(w(x_i)) - v'(e) \right]
</span></p>
<p>The optimal contract can be characterized by taking the derivative of the Lagrangian with respect to <span class="math inline">w(x_i)</span> for each outcome <span class="math inline">x_i</span>, leading to the following condition:</p>
<p><span id="eq-op_sharing"><span class="math display">
\frac{B'(x_i - w(x_i))}{U'(w(x_i))} = \lambda + \mu \frac{p_i'(e)}{p_i(e)}
\tag{2}</span></span></p>
<p>If <span class="math inline">\mu = 0</span>, the solution corresponds to the <strong>first-best solution</strong>, where the agent’s actions align perfectly with the principal’s objectives. However, as demonstrated by <span class="citation" data-cites="Holmstrom_1979">Holmström (<a href="#ref-Holmstrom_1979" role="doc-biblioref">1979</a>)</span>, if the principal seeks to motivate effort beyond the minimum, <span class="math inline">\mu &gt; 0</span>. In this case, the optimal risk-sharing depends on the sign and magnitude of <span class="math inline">\frac{p_i'(e)}{p_i(e)}</span>.</p>
<p>Statistically, <span class="math inline">\frac{p_i'(e)}{p_i(e)}</span> can be interpreted as how informative the outcome <span class="math inline">x_i</span> is about the agent’s effort level <span class="math inline">e</span> <span class="citation" data-cites="Milgrom_1981">(<a href="#ref-Milgrom_1981" role="doc-biblioref">Milgrom 1981</a>)</span>. The principal rewards outcomes that are more likely when higher effort levels are exerted (<span class="math inline">p_i'(e) &gt; 0</span>).</p>
<p>Finally, the shape of the optimal contract depends on the principal’s and agent’s utility functions as well as the probability distribution of outcomes. In particular, if <span class="math inline">\frac{p_i'(e)}{p_i(e)}</span> is increasing in the outcome, satisfying the <strong>monotone likelihood ratio condition</strong> (MLRC), the contract is likely to be monotonic in the outcome, ensuring higher outcomes correspond to higher compensations.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Linearity in the Outcome
</div>
</div>
<div class="callout-body-container callout-body">
<p>Even if the likelihood ratio is monotonic and linear in the outcome, this would not imply that the optimal compensation is also linear in the outcome. As <a href="#eq-op_sharing" class="quarto-xref">Equation&nbsp;2</a> shows, the shape of the contract also depends on the preference functions of the agent and the principal.</p>
</div>
</div>
<p>For example, assuming the the principal is risk neutral and the agent’s has an hyperbolic absolute risk aversion (HARA) utility function, then the optimal compensation is a concave function of the outcome, as shown in <a href="#eq-hara" class="quarto-xref">Equation&nbsp;3</a>.</p>
<p><span id="eq-hara"><span class="math display">
\begin{align*}
U(x) &amp;=\frac{1}{1-\gamma}\left(\delta_0+\delta_1 x\right)^{(1-\gamma)}\\
w^*(x) &amp;= -\frac{ \delta_0}{ \delta_1 x} + \delta_1^{(1-\gamma)/\gamma} \left[ \lambda + \mu \frac{p_i'(e)}{p_i(e)} \right]^{1/\gamma}
\end{align*}
\tag{3}</span></span></p>
<p>Thus, the optimal contract is linear in the outcome if <span class="math inline">\gamma=1</span> (e.g., logarithmic utility function), and concave (convex) if <span class="math inline">\gamma&gt;1</span> (<span class="math inline">\gamma&lt;1</span>).</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Limited Liability
</div>
</div>
<div class="callout-body-container callout-body">
<p>In many instances, the optimal compensation needs to be bounded below given limited liability or wealth constraints of the agent. The problem is that <a href="#eq-op_sharing" class="quarto-xref">Equation&nbsp;2</a> implies penalization to the agent for bad outcomes. Therefore, the optimal compensation is often nondifferentiable and has a piecewise linear form. See <span class="citation" data-cites="Mirrlees_1974">Mirrlees (<a href="#ref-Mirrlees_1974" role="doc-biblioref">1974</a>)</span>.</p>
</div>
</div>
</section>
<section id="sec-general_measures" class="level2" data-number="2.5">
<h2 data-number="2.5" class="anchored" data-anchor-id="sec-general_measures"><span class="header-section-number">2.5</span> Accounting performance measures</h2>
<p>Now let’s add an additional performance measure to the model to check in which conditions they reduced the welfare loss relative to the first-best solution. This will be the case if the new measure increases the agent’s incentive to exert effort or improve the risk-sharing between the principal and the agent. Be <span class="math inline">y</span> the additional performance measure. In this case, <a href="#eq-op_sharing" class="quarto-xref">Equation&nbsp;2</a> becomes</p>
<p><span id="eq-op_sharing_2"><span class="math display">
\frac{B'(x_i - w(x_i,y_i))}{U'(w(x_i,y_i)) }= \lambda + \mu \frac{p_i'(x,y;e)}{p_i(x,y;e)}
\tag{4}</span></span></p>
<p>Thus, the optimal contract depends on the performance metric if <span class="math inline">\frac{p_i'(x,y;e)}{p_i(x,y;e)}</span> also depends on <span class="math inline">y</span>. However, if <span class="math inline">x</span> is a sufficient statistic for <span class="math inline">x</span> and <span class="math inline">y</span> with respect to <span class="math inline">e</span>, then the optimal contract is independent of <span class="math inline">y</span>. This is called Holmstrom’s informativeness condition <span class="citation" data-cites="Holmstrom_1979">(<a href="#ref-Holmstrom_1979" role="doc-biblioref">Holmström 1979</a>)</span>.</p>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Sufficient Statistic
</div>
</div>
<div class="callout-body-container callout-body">
<p>If <span class="math inline">x=e+a_1</span> and <span class="math inline">y=x+a_2</span>, where <span class="math inline">a_1</span> and <span class="math inline">a_2</span> are independent random variables, then <span class="math inline">x</span> is a <strong>sufficient statistic</strong> for <span class="math inline">x</span> and <span class="math inline">y</span> with respect to <span class="math inline">e</span>. In other words, <span class="math inline">y</span> does not add any information about <span class="math inline">e</span> that is not already contained in <span class="math inline">x</span>.</p>
</div>
</div>
<section id="optimal-contract-and-linear-aggregation" class="level3" data-number="2.5.1">
<h3 data-number="2.5.1" class="anchored" data-anchor-id="optimal-contract-and-linear-aggregation"><span class="header-section-number">2.5.1</span> Optimal Contract and Linear Aggregation</h3>
<p>Accounting systems aggregate performance measures to reduce the complexity of reporting every individual transaction or piece of non-financial information. The aggregation arises because it would be both costly and unrealistic to report all basic transactions. In practice, accountants aggregate these performance measures <strong>linearly</strong>, typically assigning <strong>equal weights</strong> to each component. For example, total cost is the sum of each cost item, and net benefits are calculated as revenues minus expenses. These aggregated measures are often used in performance evaluations and compensation schemes.</p>
<p>However, the linear aggregation of performance measures with equal weights raises an important question: to what extent does contract theory support this approach? <span class="citation" data-cites="Banker_1989">Banker and Datar (<a href="#ref-Banker_1989" role="doc-biblioref">1989</a>)</span> provides theoretical support for the <strong>linear aggregation</strong> of performance measures but also highlights that the assumption of <strong>equal weights</strong> is rarely optimal. According to their analysis, the weights assigned to different components of a performance measure should reflect their <strong>signal-to-noise ratio</strong> (the sensitivity of the measure to effort relative to its variance). Only in cases where the signal-to-noise ratio is the same for all components can the equal weights assumption be considered optimal.</p>
<p>To illustrate this, consider the principal-agent framework where the principal is risk-neutral, and there are two performance metrics: <span class="math inline">x</span> and <span class="math inline">y</span>. We will continue considering <span class="math inline">x</span> to be the outcome, which as an observable variable it can also play the role of a performance metric. The optimal contract is derived from <a href="#eq-op_sharing_2" class="quarto-xref">Equation&nbsp;4</a>, which yields:</p>
<p><span class="math display">
w^*(x,y)= W \left[ \lambda + \mu \frac{p_i'(x,y;e)}{p_i(x,y;e)} \right]
</span></p>
<p>where <span class="math inline">W</span> is the inverse of the agent’s marginal utility function. We define a new compensation function <span class="math inline">s(\pi)</span> that depends on an <strong>aggregate performance measure</strong> <span class="math inline">\pi=\pi(x,y)</span>, where:</p>
<p><span class="math display">
\pi(x,y)=\lambda + \mu \frac{p_i'(x,y;e)}{p_i(x,y;e)}
</span></p>
<p>For many probability distributions, such as those from the <strong>exponential family</strong>, the likelihood ratio is linear in both <span class="math inline">x</span> and <span class="math inline">y</span>. Therefore, the optimal contract supports the linear aggregation of performance metrics in those cases.</p>
</section>
<section id="optimal-weights-for-aggregation" class="level3" data-number="2.5.2">
<h3 data-number="2.5.2" class="anchored" data-anchor-id="optimal-weights-for-aggregation"><span class="header-section-number">2.5.2</span> Optimal Weights for Aggregation</h3>
<p>In determining the optimal weights for these performance metrics, <span class="citation" data-cites="Banker_1989">Banker and Datar (<a href="#ref-Banker_1989" role="doc-biblioref">1989</a>)</span> shows that for the exponential family of distributions, when both metrics are independently distributed given the agent’s effort, the optimal weights are proportional to (1) the sensitivity of the metric to the agent’s effort and (2) the inverse of the variance of the performance metrics. Specifically, if we denote the weights as <span class="math inline">\beta_x</span> and <span class="math inline">\beta_y</span>, the optimal weights are given by:</p>
<p><span id="eq-optimal_beta"><span class="math display">
\beta_x  = \frac{\frac{\partial E(x;e)}{ \partial e} var(y) }{ \left[ var(x)+var(y) \right]}
\tag{5}</span></span></p>
<p>and</p>
<p><span class="math display">
\beta_y  = \frac{\frac{\partial E(y;e)}{ \partial e} var(x) }{ \left[ var(x)+var(y) \right]}
</span></p>
<p>The <strong>relative weights</strong> between the two performance metrics can be expressed as:</p>
<p><span id="eq-optimal_weights"><span class="math display">
\frac{\beta_x}{\beta_y} = \frac{\frac{\partial E(x;e)}{ \partial e}}{var(x)} \cdot \frac{var(y)}{\frac{\partial E(y;e)}{ \partial e}}
\tag{6}</span></span></p>
<p>This shows that the optimal weights for performance measures depend on both the <strong>sensitivity</strong> of each metric to the agent’s effort and the <strong>variance</strong> of the performance metrics. In cases where the signal-to-noise ratio differs across metrics, assigning equal weights leads to suboptimal outcomes. Therefore, a key takeaway is that optimal weighting adjusts based on the <strong>informational value</strong> of each performance measure in relation to the agent’s effort.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
The relevance of variables not controlled by the agent
</div>
</div>
<div class="callout-body-container callout-body">
<p>If the principal or other agent invest in technology or capital such as the agent’s effort is more productive or the performance metric is more sensitive to its effort, then it is optimal to introduce those variables into the contract even though are not controlled by the agent. In this case, the optimal contract adjusts the compensation to subtract the principal’s investment effect on the mean outcome or adjusts the weights of the performance metrics to reflect their new informativeness.</p>
</div>
</div>
<p>How the optimal contract should weights performance metrics that are correlated? In that case, <a href="#eq-optimal_weights" class="quarto-xref">Equation&nbsp;6</a> is rewritten as</p>
<p><span id="eq-optimal_weights_2"><span class="math display">
\frac{\beta_x}{\beta_y} = \frac{ \frac{\partial E(x;e)}{\partial e} - \frac{cov(x,y)}{var(y)}\frac{\partial E(y;e)}{\partial e} }{var(x)} \frac{var(y)}{\frac{\partial E(y;e)}{\partial e} - \frac{cov(x,y)}{var(x)}\frac{\partial E(x;e)}{\partial e}}
\tag{7}</span></span></p>
<p>so, even if the agent does not control <span class="math inline">y</span> (e.g., <span class="math inline">\frac{\partial E(y;e)}{\partial e}=0</span>) then both metrics should be included in the contract with weights that reflect the correlation between them.</p>
<p><span class="math display">
\frac{\beta_x}{\beta_y} = -\frac{var(y)}{covar(x,y)}
</span></p>
<p>Thus, if the metrics are positively correlated, then their weights have opposite signs. The interpretation is that the positive correlation is driven by an exogenous common factor, and by adjusting <span class="math inline">y</span> with a negative weight some of the noise driven by the common factor in <span class="math inline">x</span> is removed.</p>
</section>
</section>
</section>
<section id="linear-exponential-normal-len-moral-hazard-models" class="level1" data-number="3">
<h1 data-number="3"><span class="header-section-number">3</span> Linear-Exponential-Normal (LEN) Moral Hazard Models</h1>
<p>In this section, we develop a widely used model in principal-agent theory that assumes <strong>linear contracts</strong>, <strong>normally distributed performance</strong>, and <strong>exponential utility</strong> for the agent. The performance outcome is modeled as the sum of effort (in monetary terms) and noise:</p>
<p><span class="math display">
x = e + \epsilon \quad \text{with} \quad \epsilon \sim N(0, \sigma^{2})
</span></p>
<p>We assume that the principal is <strong>risk-neutral</strong>, meaning they are indifferent to risk and only care about the expected cost of motivating the agent. The agent, on the other hand, has <strong>constant absolute risk aversion (CARA)</strong>, represented by a negative exponential utility function:</p>
<p><span class="math display">
u(w, e) = -e^{-\eta\left[w - \psi(e)\right]} \quad \text{with} \quad \psi(e) = \frac{1}{2}ce^{2}
</span></p>
<p>Here, <span class="math inline">\eta</span> denotes the agent’s risk aversion, and <span class="math inline">\psi(e)</span> represents the cost of effort.</p>
<p>In these models, the <strong>compensation contract</strong> follows a linear form:</p>
<p><span class="math display">
w = t + sx
</span></p>
<p>where <span class="math inline">t</span> is a fixed component, and <span class="math inline">s</span> is the performance-related component.</p>
<section id="agents-problem-1" class="level2" data-number="3.1">
<h2 data-number="3.1" class="anchored" data-anchor-id="agents-problem-1"><span class="header-section-number">3.1</span> Agent’s Problem</h2>
<p>Using the property of normally distributed noise, <span class="math inline">\mathbb{E}\left[e^{k\epsilon}\right] = e^{k^{2}\frac{\sigma^{2}}{2}}</span> for any <span class="math inline">k</span>, we derive the agent’s expected utility:</p>
<p><span class="math display">
\mathbb{E}\left[u(w, e)\right] = -e^{-\eta\left[t + se - \frac{1}{2}ce^{2} - s^{2}\eta\frac{\sigma^{2}}{2}\right]}
</span></p>
<p>The agent’s incentive compatibility constraint (ICC) can be reformulated as:</p>
<p><span class="math display">
e \in \arg\max \hat{w}(e) = t + se - \frac{1}{2}ce^{2} - s^{2}\eta\frac{\sigma^{2}}{2}
</span></p>
<p>Solving the first-order condition for effort, we obtain the <strong>optimal effort</strong>:</p>
<p><span class="math display">
e^* = \frac{s}{c}
</span></p>
<p>Thus, for any given incentive <span class="math inline">s</span>, the principal can anticipate the agent’s effort level.</p>
</section>
<section id="principals-problem-1" class="level2" data-number="3.2">
<h2 data-number="3.2" class="anchored" data-anchor-id="principals-problem-1"><span class="header-section-number">3.2</span> Principal’s Problem</h2>
<p>The principal’s objective is to maximize their expected payoff, which is the performance outcome minus the agent’s compensation. The principal’s optimization problem is written as:</p>
<p><span id="eq-principal_problem_len"><span class="math display">
\begin{aligned}
    \underset{t,s,e}{\max} &amp; \quad \mathbb{E}[x(e^*) - t - s[x(e^*)]] &amp;  \\
    \text{subject to:} &amp; \quad t + s[e^*] - \frac{1}{2}c[e^*]^{2} - s^{2}\eta\frac{\sigma^{2}}{2} = \overline{w} &amp; \quad  \text{(PC)} \\
\end{aligned}
\tag{8}</span></span></p>
</section>
<section id="optimal-compensation-terms-1" class="level2" data-number="3.3">
<h2 data-number="3.3" class="anchored" data-anchor-id="optimal-compensation-terms-1"><span class="header-section-number">3.3</span> Optimal Compensation Terms</h2>
<p>Solving <a href="#eq-principal_problem_len" class="quarto-xref">Equation&nbsp;8</a> yields the <strong>optimal compensation terms</strong> for the fixed component <span class="math inline">t</span> and the performance-related component <span class="math inline">s</span>:</p>
<p><span class="math display">
\begin{align*}
s^{*} &amp;= \frac{1}{1 + c\eta\sigma^{2}} \\
t^{*} &amp;= \overline{w} - \frac{1 - c\eta\sigma^{2}}{2c\left(1 + c\eta\sigma^{2}\right)^{2}}
\end{align*}
</span></p>
<p>The results indicate that the <strong>variable compensation</strong> (<span class="math inline">s^*</span>) (performance-related incentive) is higher when:</p>
<ul>
<li>The <strong>cost of effort</strong> <span class="math inline">c</span> is low,</li>
<li>The agent’s <strong>degree of risk aversion</strong> <span class="math inline">\eta</span> is low,</li>
<li>The <strong>variance</strong> of the performance measure <span class="math inline">\sigma^{2}</span> is low.</li>
</ul>
<p>The following graphs shows the comparative statics of the optimal contract terms and utilities for different values of <span class="math inline">\sigma</span>.</p>
<div id="27f49701" class="cell" data-execution_count="1">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a>c<span class="op">=</span><span class="fl">0.8</span> <span class="co"># cost of effort</span></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a>eta<span class="op">=</span><span class="fl">1.5</span> <span class="co"># risk aversion</span></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>w<span class="op">=</span><span class="dv">1</span>     <span class="co"># reservation utility</span></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot s,t,and total, for different values of sigma </span></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a>sigma <span class="op">=</span> np.linspace(<span class="dv">0</span>,<span class="fl">2.5</span>,<span class="dv">10</span>)</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a>s <span class="op">=</span> <span class="dv">1</span><span class="op">/</span>(<span class="dv">1</span><span class="op">+</span>c<span class="op">*</span>eta<span class="op">*</span>sigma<span class="op">**</span><span class="dv">2</span>)</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>t <span class="op">=</span> w <span class="op">-</span> (<span class="dv">1</span><span class="op">-</span>c<span class="op">*</span>eta<span class="op">*</span>sigma<span class="op">**</span><span class="dv">2</span>)<span class="op">/</span>(<span class="dv">2</span><span class="op">*</span>c<span class="op">*</span>(<span class="dv">1</span><span class="op">+</span>c<span class="op">*</span>eta<span class="op">*</span>sigma<span class="op">**</span><span class="dv">2</span>)<span class="op">**</span><span class="dv">2</span>) </span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a>total <span class="op">=</span> t <span class="op">+</span> s </span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a>effort <span class="op">=</span> s<span class="op">/</span>c </span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a>plt.plot(sigma, s, label<span class="op">=</span><span class="st">'s'</span>)</span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a>plt.plot(sigma, t, label<span class="op">=</span><span class="st">'t'</span>)</span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a>plt.plot(sigma, total, label<span class="op">=</span><span class="st">'total'</span>)</span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a>plt.plot(sigma, effort, label<span class="op">=</span><span class="st">'effort'</span>, linestyle<span class="op">=</span><span class="st">'dashed'</span>)</span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a><span class="co"># render sigma symbol in the x label</span></span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Value of $\sigma$'</span>)</span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Value'</span>)</span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Optimal contract terms'</span>)</span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="mora_hazard_files/figure-html/cell-2-output-1.png" width="589" height="449" class="figure-img"></p>
</figure>
</div>
</div>
</div>
<div id="064db480" class="cell" data-execution_count="2">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="co"># plot the utility of the agent and principal for different values of sigma</span></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>u_agent <span class="op">=</span> <span class="op">-</span>np.exp(<span class="op">-</span>eta<span class="op">*</span>(t<span class="op">+</span>s<span class="op">*</span>effort<span class="op">-</span><span class="fl">0.5</span><span class="op">*</span>c<span class="op">*</span>effort<span class="op">**</span><span class="dv">2</span><span class="op">-</span>s<span class="op">**</span><span class="dv">2</span><span class="op">*</span>eta<span class="op">*</span>sigma<span class="op">**</span><span class="dv">2</span><span class="op">/</span><span class="dv">2</span>)) </span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>u_principal <span class="op">=</span> effort<span class="op">-</span>t<span class="op">-</span>s<span class="op">*</span>effort</span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a>plt.plot(sigma, u_agent, label<span class="op">=</span><span class="st">'Agent'</span>)</span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>plt.plot(sigma, u_principal, label<span class="op">=</span><span class="st">'Principal'</span>)</span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Value of $\sigma$'</span>)</span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Utility'</span>)</span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Agent and Principal utility'</span>)</span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="mora_hazard_files/figure-html/cell-3-output-1.png" width="600" height="449" class="figure-img"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="accounting-perfomance-measures" class="level2" data-number="3.4">
<h2 data-number="3.4" class="anchored" data-anchor-id="accounting-perfomance-measures"><span class="header-section-number">3.4</span> Accounting Perfomance Measures</h2>
<p>As in <a href="#sec-general_measures" class="quarto-xref">Section&nbsp;2.5</a>, assume that <span class="math inline">x</span> is the outcome and <span class="math inline">y</span> is an additional performance measure, such that:</p>
<p><span class="math display">
x = e + \epsilon_x \quad \text{and} \quad y = 2e + \epsilon_y
</span></p>
<p>where <span class="math inline">\epsilon_x</span> and <span class="math inline">\epsilon_y</span> are jointly normally distributed with zero means. The joint distribution function <span class="math inline">f(x, y; e)</span> is a <strong>bivariate normal distribution</strong> with the following properties:</p>
<ul>
<li><strong>Mean vector</strong>:</li>
</ul>
<p><span class="math display">
\mu_{x, y} = \left(\begin{array}{c} e \\ 2e \end{array}\right)
</span></p>
<ul>
<li><strong>Covariance matrix</strong>:</li>
</ul>
<p><span class="math display">
\Sigma_{x, y} = \left(\begin{array}{cc} \sigma_x^2 &amp; \rho \sigma_x \sigma_y \\ \rho \sigma_x \sigma_y &amp; \sigma_y^2 \end{array}\right)
</span></p>
<p>where <span class="math inline">\sigma_x^2</span> is the variance of <span class="math inline">\epsilon_x</span>, <span class="math inline">\sigma_y^2</span> is the variance of <span class="math inline">\epsilon_y</span>, and <span class="math inline">\rho</span> is the correlation coefficient between <span class="math inline">\epsilon_x</span> and <span class="math inline">\epsilon_y</span>.</p>
<p>Notice that the additional metric <span class="math inline">y</span> is, on average, more sensitive to the agent’s effort than the outcome <span class="math inline">x</span>, since:</p>
<p><span class="math display">
\frac{\partial E[y(e)]}{\partial e} &gt; \frac{\partial E[x(e)]}{\partial e}
</span></p>
<p>This situation can arise in scenarios such as a merchandising company, where <span class="math inline">x</span> represents net profits, but the agent has limited control over the cost of goods sold (e.g., limited negotiation power with suppliers), while the agent’s effort directly influences sales <span class="math inline">y</span>.</p>
<section id="aggregation-of-performance-measures" class="level3" data-number="3.4.1">
<h3 data-number="3.4.1" class="anchored" data-anchor-id="aggregation-of-performance-measures"><span class="header-section-number">3.4.1</span> Aggregation of Performance Measures</h3>
<p>The <strong>accounting system</strong> aggregates both metrics <span class="math inline">x</span> and <span class="math inline">y</span> into a single performance measure <span class="math inline">\pi = \pi(x, y)</span>, which is used to determine the optimal compensation terms <span class="math inline">w(\pi)</span>. The relative weights for <span class="math inline">x</span> and <span class="math inline">y</span>, derived from <a href="#eq-optimal_weights_2" class="quarto-xref">Equation&nbsp;7</a>, are given by:</p>
<p><span class="math display">
\frac{\beta_x}{\beta_y} = \frac{1 - 2\frac{\rho \sigma_x \sigma_y}{\sigma_y^2}}{\sigma_x^2} \cdot \frac{\sigma_y^2}{2 - \frac{\rho \sigma_x \sigma_y}{\sigma_x^2}}
</span></p>
<p>Let’s see the comparative statics of the optimal weights for different values of <span class="math inline">\rho</span> and <span class="math inline">\sigma_y</span>. First, let’s assume that both metrics have the same noise, <span class="math inline">\sigma_x=\sigma_y=1.25</span>.</p>
<div id="b1f7aa1c" class="cell" data-execution_count="3">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="co"># plot the beta_x/beta_y for different values of rho </span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>rho <span class="op">=</span> np.linspace(<span class="op">-</span><span class="dv">1</span>,<span class="dv">1</span>,<span class="dv">20</span>)</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a>sigma_y <span class="op">=</span> <span class="fl">1.25</span></span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a>sigma_x <span class="op">=</span> <span class="fl">1.25</span></span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a><span class="co"># subplot for rho</span></span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a>beta_rho <span class="op">=</span> (<span class="dv">1</span><span class="op">-</span><span class="dv">2</span><span class="op">*</span>(rho<span class="op">*</span>sigma_x<span class="op">*</span>sigma_y)<span class="op">/</span>(sigma_y)<span class="op">**</span><span class="dv">2</span>)<span class="op">/</span>(sigma_x<span class="op">**</span><span class="dv">2</span>)<span class="op">*</span>(sigma_y<span class="op">**</span><span class="dv">2</span>)<span class="op">/</span>(<span class="dv">2</span><span class="op">-</span>(rho<span class="op">*</span>sigma_x<span class="op">*</span>sigma_y)<span class="op">/</span>(sigma_x)<span class="op">**</span><span class="dv">2</span>)</span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a>plt.plot(rho, beta_rho)</span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'correlation coefficient'</span>)</span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a><span class="co"># add vertical line in x=0</span></span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a>plt.axvline(x<span class="op">=</span><span class="dv">0</span>, color<span class="op">=</span><span class="st">'r'</span>, linestyle<span class="op">=</span><span class="st">'--'</span>)</span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a><span class="co">## add subtitle</span></span>
<span id="cb3-12"><a href="#cb3-12" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Relative Optimal Weights'</span>)</span>
<span id="cb3-13"><a href="#cb3-13" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="mora_hazard_files/figure-html/cell-4-output-1.png" width="590" height="449" class="figure-img"></p>
</figure>
</div>
</div>
</div>
<p>so, if <span class="math inline">\rho=0</span>, the optimal weight for <span class="math inline">x</span> is half of the weight for <span class="math inline">y</span>, as this second signal is more sensitive to effort and has the same noise. If <span class="math inline">\rho=-1</span>, then both both signal have full positive weight in the contract. If <span class="math inline">\rho=1</span>, then the signals are substracted from each other in the contract to remove the common noise.</p>
<p>Now, let’s see the comparative statics for different values of <span class="math inline">\sigma_y</span>, considering <span class="math inline">\rho=0</span> and <span class="math inline">\sigma_x=1.25</span>.</p>
<div id="11a7ee56" class="cell" data-execution_count="4">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="co"># plot the beta_x/beta_y for different values of sigma_y</span></span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>rho<span class="op">=</span><span class="dv">0</span></span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>sigma_y <span class="op">=</span> np.linspace(<span class="fl">0.1</span>,<span class="fl">2.5</span>,<span class="dv">10</span>)</span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a>sigma_x <span class="op">=</span> <span class="fl">1.25</span></span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a><span class="co"># plot for sigma_y</span></span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a>beta_sigma_y <span class="op">=</span> (<span class="dv">1</span><span class="op">-</span><span class="dv">2</span><span class="op">*</span>(rho<span class="op">*</span>sigma_x<span class="op">*</span>sigma_y)<span class="op">/</span>(sigma_y)<span class="op">**</span><span class="dv">2</span>)<span class="op">/</span>(sigma_x<span class="op">**</span><span class="dv">2</span>)<span class="op">*</span>(sigma_y<span class="op">**</span><span class="dv">2</span>)<span class="op">/</span>(<span class="dv">2</span><span class="op">-</span>(rho<span class="op">*</span>sigma_x<span class="op">*</span>sigma_y)<span class="op">/</span>(sigma_x)<span class="op">**</span><span class="dv">2</span>)</span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a>plt.axvline(x<span class="op">=</span><span class="fl">1.25</span>, color<span class="op">=</span><span class="st">'r'</span>, linestyle<span class="op">=</span><span class="st">'--'</span>)</span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a>plt.plot(sigma_y, beta_sigma_y)</span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Value of $\sigma_y$'</span>)</span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Relative Optimal Weights'</span>)</span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="mora_hazard_files/figure-html/cell-5-output-1.png" width="579" height="453" class="figure-img"></p>
</figure>
</div>
</div>
</div>
<p>Here the red line despicts the same situation than in the previous plot, meaning that when both signals have the same noise. The optimal weight for <span class="math inline">x</span> is half of the weight for <span class="math inline">y</span>. If <span class="math inline">\sigma_y</span> gets closer to zero, then the weight for <span class="math inline">x</span> decreases as <span class="math inline">y</span> gets a better relative signal-to-noise ratio.</p>
</section>
</section>
<section id="optimal-contract-with-additional-performance-measures" class="level2" data-number="3.5">
<h2 data-number="3.5" class="anchored" data-anchor-id="optimal-contract-with-additional-performance-measures"><span class="header-section-number">3.5</span> Optimal Contract with additional Performance Measures</h2>
<p>To evaluate how the optimal contract changes with the use of the aggregate performance metric we should compute the aggregated signal <span class="math inline">\pi(x,y)=\beta_x x+ \beta_y y</span> using <a href="#eq-optimal_beta" class="quarto-xref">Equation&nbsp;5</a>. For simplicity, assume <span class="math inline">\rho=0</span>.</p>
<p><span class="math display">
\pi(x,y)=\frac{\sigma_y^2}{\sigma_x^2+\sigma_y^2} x+ 2 \frac{\sigma_x^2}{\sigma_x^2+\sigma_y^2} y
</span></p>
<p>Now, the compensation functions depens on the aggregated signal <span class="math inline">\pi</span> (rather than on the output <span class="math inline">x</span>), meaning that now <span class="math inline">w(\pi)=t+s\pi</span>. Notice that <span class="math inline">\pi \sim N(\mu_{\pi},\sigma_{\pi}^2)</span>, with</p>
<p><span class="math display">
\begin{align*}
\mu_{\pi}(e) &amp;= \frac{e}{\sigma_x^2+\sigma_y^2} \left[  \sigma_y^2+4\sigma_x^2 \right]\\
\sigma_{\pi}^2(e) &amp;= \frac{\sigma_x^2\sigma_y^2}{(\sigma_x^2+\sigma_y^2)^2}\left[  \sigma_y^2+4\sigma_x^2 \right]
\end{align*}
</span></p>
<p>We can reformulate agent’s problem as <span class="math display">
e \in\arg\max\hat{w}(e)=t+s\mu_{\pi}-\frac{1}{2}ce^{2}-s^{2}\eta\frac{\sigma_{\pi}^2 }{2}
</span></p>
<p>obtaining optimal effort equals to <span id="eq-effort_with_signals"><span class="math display">
e^*=\frac{s}{c} \frac{\partial \mu_{\pi}(e)}{\partial e} =\frac{s}{c} \left[\frac{\sigma_y^2+4\sigma_x^2}{\sigma_x^2+\sigma_y^2} \right]
\tag{9}</span></span></p>
<p>Again, for any given performance incentive <span class="math inline">s</span>, the principal can infer the optimal effort of the agent. Relative to our initial result (<span class="math inline">e^*=s/c</span>), <a href="#eq-effort_with_signals" class="quarto-xref">Equation&nbsp;9</a> shows that having the aggregated metric <span class="math inline">\pi</span> in the contract increases the optimal effort level for any given value of performance incentive <span class="math inline">s</span> as much as the sensitivity of expected value of <span class="math inline">\pi</span> to the agent’s effort is higher than one.</p>
<p>The updated principal’s problem is <span class="math display">
\begin{align*}
\underset{t, s}{\max} \quad &amp; \mathbb{E}[x(e^*) - t - s \cdot x(e^*)] \\
\text{subject to:} \quad &amp; t + s \cdot e^* - \frac{1}{2} c (e^*)^2 - s^2 \eta \frac{\sigma_{\pi}^2(e^*)}{2} = \overline{w}
\end{align*}
</span> Obtaining</p>
<p><span class="math display">
s^* = \frac{\frac{\partial \mu_{\pi}(e)}{\partial e}}{\left(\frac{\partial \mu_{\pi}(e)}{\partial e}\right)^2+c n \sigma_{\pi}^2} =\frac{\frac{\sigma_y^2 + 4\sigma_x^2}{\sigma_x^2 + \sigma_y^2}}{\left( \frac{\sigma_y^2 + 4\sigma_x^2}{\sigma_x^2 + \sigma_y^2} \right)^2 + c n \sigma_{\pi}^2}
</span></p>
<p>The next figure compares the optimal effort and compensation terms for different values of <span class="math inline">\sigma_x</span> with our previous result for the case without the additional metric.</p>
<div id="9f74bc37" class="cell" data-execution_count="5">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a>c<span class="op">=</span><span class="fl">0.8</span> <span class="co"># cost of effort</span></span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>eta<span class="op">=</span><span class="fl">1.5</span> <span class="co"># risk aversion</span></span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a>w<span class="op">=</span><span class="dv">1</span>     <span class="co"># reservation utility</span></span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a><span class="co"># initial contract</span></span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a>sigma_x <span class="op">=</span> np.linspace(<span class="dv">0</span>,<span class="fl">2.5</span>,<span class="dv">10</span>)</span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a>s_old <span class="op">=</span> <span class="dv">1</span><span class="op">/</span>(<span class="dv">1</span><span class="op">+</span>c<span class="op">*</span>eta<span class="op">*</span>sigma_x<span class="op">**</span><span class="dv">2</span>)</span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a>t_old <span class="op">=</span> w <span class="op">-</span> (<span class="dv">1</span><span class="op">-</span>c<span class="op">*</span>eta<span class="op">*</span>sigma_x<span class="op">**</span><span class="dv">2</span>)<span class="op">/</span>(<span class="dv">2</span><span class="op">*</span>c<span class="op">*</span>(<span class="dv">1</span><span class="op">+</span>c<span class="op">*</span>eta<span class="op">*</span>sigma_x<span class="op">**</span><span class="dv">2</span>)<span class="op">**</span><span class="dv">2</span>) </span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a>effort_old <span class="op">=</span> s_old<span class="op">/</span>c </span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a><span class="co"># new contract</span></span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a>sigma_y <span class="op">=</span> <span class="fl">1.25</span></span>
<span id="cb5-11"><a href="#cb5-11" aria-hidden="true" tabindex="-1"></a>sigma_pi2<span class="op">=</span> (sigma_x<span class="op">**</span><span class="dv">2</span><span class="op">*</span>sigma_y<span class="op">**</span><span class="dv">2</span>)<span class="op">/</span>((sigma_x<span class="op">**</span><span class="dv">2</span><span class="op">+</span>sigma_y<span class="op">**</span><span class="dv">2</span>)<span class="op">**</span><span class="dv">2</span>)<span class="op">*</span>(sigma_y<span class="op">**</span><span class="dv">2</span><span class="op">+</span><span class="dv">4</span><span class="op">*</span>sigma_x<span class="op">**</span><span class="dv">2</span>)</span>
<span id="cb5-12"><a href="#cb5-12" aria-hidden="true" tabindex="-1"></a>pi_sensitivity <span class="op">=</span> (sigma_y<span class="op">**</span><span class="dv">2</span><span class="op">+</span><span class="dv">4</span><span class="op">*</span>sigma_x<span class="op">**</span><span class="dv">2</span>)<span class="op">/</span>(sigma_x<span class="op">**</span><span class="dv">2</span><span class="op">+</span>sigma_y<span class="op">**</span><span class="dv">2</span>)</span>
<span id="cb5-13"><a href="#cb5-13" aria-hidden="true" tabindex="-1"></a>s_new<span class="op">=</span> pi_sensitivity<span class="op">/</span>(pi_sensitivity<span class="op">**</span><span class="dv">2</span><span class="op">+</span>c<span class="op">*</span>eta<span class="op">*</span>sigma_pi2)</span>
<span id="cb5-14"><a href="#cb5-14" aria-hidden="true" tabindex="-1"></a>effort_new<span class="op">=</span> (s_new<span class="op">/</span>c)<span class="op">*</span>pi_sensitivity</span>
<span id="cb5-15"><a href="#cb5-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-16"><a href="#cb5-16" aria-hidden="true" tabindex="-1"></a>plt.plot(sigma_x, s_old, label<span class="op">=</span><span class="st">'s'</span>, linestyle<span class="op">=</span><span class="st">'solid'</span>,color<span class="op">=</span><span class="st">'blue'</span>)</span>
<span id="cb5-17"><a href="#cb5-17" aria-hidden="true" tabindex="-1"></a>plt.plot(sigma_x, effort_old, label<span class="op">=</span><span class="st">'effort'</span>, linestyle<span class="op">=</span><span class="st">'dashed'</span> ,color<span class="op">=</span><span class="st">'blue'</span>)</span>
<span id="cb5-18"><a href="#cb5-18" aria-hidden="true" tabindex="-1"></a>plt.plot(sigma_x, s_new, label<span class="op">=</span><span class="st">'s with additional metric'</span>, linestyle<span class="op">=</span><span class="st">'solid'</span>,color<span class="op">=</span><span class="st">'green'</span>)</span>
<span id="cb5-19"><a href="#cb5-19" aria-hidden="true" tabindex="-1"></a>plt.plot(sigma_x, effort_new, label<span class="op">=</span><span class="st">'effort with additional metric'</span>, linestyle<span class="op">=</span><span class="st">'dashed'</span>, color<span class="op">=</span><span class="st">'green'</span>)</span>
<span id="cb5-20"><a href="#cb5-20" aria-hidden="true" tabindex="-1"></a>plt.axvline(x<span class="op">=</span><span class="fl">1.25</span>, color<span class="op">=</span><span class="st">'r'</span>, linestyle<span class="op">=</span><span class="st">'--'</span>)</span>
<span id="cb5-21"><a href="#cb5-21" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb5-22"><a href="#cb5-22" aria-hidden="true" tabindex="-1"></a><span class="co"># render sigma symbol in the x label</span></span>
<span id="cb5-23"><a href="#cb5-23" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Value of $\sigma_x$'</span>)</span>
<span id="cb5-24"><a href="#cb5-24" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Value'</span>)</span>
<span id="cb5-25"><a href="#cb5-25" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Optimal contract terms'</span>)</span>
<span id="cb5-26"><a href="#cb5-26" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="mora_hazard_files/figure-html/cell-6-output-1.png" width="589" height="451" class="figure-img"></p>
</figure>
</div>
</div>
</div>
<p>We see that the introduction of the additional metric <span class="math inline">y</span> leads to two effects. First, the optimal effort increases regardless of how noisy is the outcome. Second, performance-related incentive <span class="math inline">s</span> is lower than the original case for low values of outcome volatility, but is larger when this volatility is high. This is because for low outcome volatility, the new metric is more sensitive to the agent’s effort than the output <span class="math inline">x</span> alone, being more efficient to motivate the agent. However, for high outcome volatility, the new metric is less sensitive to the agent’s effort, so the principal needs to increase the incentive to motivate the agent.</p>
</section>
<section id="suggestions-for-further-reading" class="level2" data-number="3.6">
<h2 data-number="3.6" class="anchored" data-anchor-id="suggestions-for-further-reading"><span class="header-section-number">3.6</span> Suggestions for Further Reading</h2>
<p>The literature on moral hazard has expanded the basic model in several important directions. One strand of research introduces stock-price incentives into compensation contracts, as explored by <a href="https://www.sciencedirect.com/science/article/abs/pii/016541019390004Y?via%3Dihub">Kim and Suh (1991)</a>, <a href="https://doi.org/10.1093/rfs/5.3.471">Paul (1992)</a>, <a href="https://publications.aaahq.org/accounting-review/article/80/4/1069/2836/Stock-Price-Earnings-and-Book-Value-in-Managerial">Dutta and Reichelstein (2005)</a>, and <a href="https://link.springer.com/article/10.1007/s11142-015-9339-6#Sec3">Bernardo et al.&nbsp;(2015)</a>.</p>
<p>Another line of research extends the set of actions available to managers, as highlighted by <a href="https://people.duke.edu/~qc2/BA532/1991%20JLEO%20Holmstrom%20Milgrom.pdf">Holmstrom and Milgrom (1991)</a>, <a href="https://edisciplinas.usp.br/pluginfile.php/159924/mod_resource/content/1/FX.pdf">Feltham and Xie (1994)</a>, <a href="https://doi.org/10.1016/0165-4101(93)90003-X">Bushman and Indjejikian (1993)</a>, and <a href="https://doi.org/10.1093/rfs/5.3.471">Paul (1992)</a>.</p>
<p>Finally, dynamic models of moral hazard have also been developed. Notable contributions in this area include <a href="https://www.jstor.org/stable/1913238">Holmstrom and Milgrom (1987)</a>, <a href="https://link.springer.com/article/10.1023/A:1009634201495">Dutta and Reichelstein (1999)</a>, <a href="https://link.springer.com/article/10.1007/s11142-009-9095-6">Corona (2009)</a>, <a href="https://doi.org/10.1287/mnsc.2016.2493">Cvitanić et al.&nbsp;(2016)</a>, and <a href="https://academic.oup.com/rfs/article-abstract/36/4/1408/6675503?redirectedFrom=fulltext">Ai et al.&nbsp;(2023)</a>.</p>



</section>
</section>


<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" role="doc-bibliography" id="quarto-bibliography"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list">
<div id="ref-Banker_1989" class="csl-entry" role="listitem">
Banker, Rajiv D., and Srikant M. Datar. 1989. <span>“Sensitivity, Precision, and Linear Aggregation of Signals for Performance Evaluation.”</span> <em>Journal of Accounting Research</em> 27 (1): 21–39. <a href="http://www.jstor.org/stable/2491205">http://www.jstor.org/stable/2491205</a>.
</div>
<div id="ref-Bolton_Dewatripont_2005" class="csl-entry" role="listitem">
Bolton, Patrick, and M. Dewatripont. 2005. <em>Contract Theory</em>. Cambridge, Mass: MIT Press.
</div>
<div id="ref-Holmstrom_1979" class="csl-entry" role="listitem">
Holmström, Bengt. 1979. <span>“Moral Hazard and Observability.”</span> <em>The Bell Journal of Economics</em> 10 (1): 74–91. <a href="http://www.jstor.org/stable/3003320">http://www.jstor.org/stable/3003320</a>.
</div>
<div id="ref-Lambert_2001" class="csl-entry" role="listitem">
Lambert, Richard A. 2001. <span>“Contracting Theory and Accounting.”</span> <em>Journal of Accounting and Economics</em> 32 (1–3): 3–87. <a href="https://doi.org/10.1016/S0165-4101(01)00037-4">https://doi.org/10.1016/S0165-4101(01)00037-4</a>.
</div>
<div id="ref-Milgrom_1981" class="csl-entry" role="listitem">
Milgrom, Paul R. 1981. <span>“Good News and Bad News: Representation Theorems and Applications.”</span> <em>The Bell Journal of Economics</em> 12 (2): 380–91. <a href="http://www.jstor.org/stable/3003562">http://www.jstor.org/stable/3003562</a>.
</div>
<div id="ref-Mirrlees_1974" class="csl-entry" role="listitem">
Mirrlees, James A. 1974. <span>“<span class="nocase">Notes on Welfare Economics, Information, and Uncertainty</span>.”</span> In <em><span class="nocase">Welfare, Incentives, and Taxation</span></em>. Oxford University Press. <a href="https://doi.org/10.1093/acprof:oso/9780198295211.003.0003">https://doi.org/10.1093/acprof:oso/9780198295211.003.0003</a>.
</div>
</div></section><section id="footnotes" class="footnotes footnotes-end-of-document" role="doc-endnotes"><h2 class="anchored quarto-appendix-heading">Footnotes</h2>

<ol>
<li id="fn1"><p>Additionally, if the agent has bargaining power, they could negotiate up to 161 for high effort. Analyse the Edgeworth box representation.<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section></div></main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>