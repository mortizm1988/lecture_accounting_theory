[
  {
    "objectID": "mora_hazard.html",
    "href": "mora_hazard.html",
    "title": "Contract Theory and Accounting",
    "section": "",
    "text": "Moral hazard arises when one party in a transaction can take actions that affect the value of the transaction for the other party. However, those actions are either unobservable or only imperfectly inferable by the affected party. This problem typically occurs in situations where two conditions are present: hidden action and risk aversion.\n\nHidden action: Refers to actions taken by one party that cannot be directly monitored or measured by the other party. As a result, the affected party cannot perfectly determine whether adverse outcomes are due to poor performance, lack of effort, or external factors.\nRisk aversion: At least one of the parties involved must prefer avoiding risk. They value stability and predictability, often making them cautious about transactions or agreements that expose them to unpredictable outcomes.\n\nThe moral hazard problem is fundamentally about the misalignment of incentives between parties. Specifically, the party whose actions are unobservable might not have adequate incentives to act in the best interest of the other party.\nSolving Moral hazard conflicts implies solving two challenges:\n\nProvision of adequate incentives: Designing mechanisms to motivate the party taking the hidden action to behave in a way that aligns with the other party’s goals.\nEfficient risk distribution: Finding a balance in how risk is shared between the parties, so that each party bears the appropriate level of risk without undermining incentives.\n\nThese two objectives often conflict. There is a substitution effect: when one party is overly shielded from risk, they may lack the incentive to take efficient actions that benefit the other party. As a result, designing an optimal compensation or incentive scheme requires balancing risk-sharing with providing the right incentives.\nThe focus of this class will be moral hazard conflicts arising within a firm, typically between a shareholder (the pricipal) and a manager (the agent). The principal aims to hire the agent for running a risky project, and offers the agent a contract which stablishes the agent’s compensation conditional on the outcome of the risky project. The agent first decides whether to accept the contract and then how much effort put into managing the project. The principal requires informations to infer the value of the project’s outcome and the agent’s effort to be able to compute the agent’s compensation and its own net profits.\nIn this setting, accounting is naturally embedded into moral hazard problems. Accounting information must have several key characteristics to be useful for decision-making. Accounting information must be relevant, comparable, verifiable, and timeliness. Scholars have studied how these characteristics can be used to design optimal contracts that mitigate moral hazard problems.\nThis reading note starts by developing a simple example of a moral hazard problem to illustrate the nature of the problem and the trade-offs involved in solving it. We then move on to a more general moral hazard model, allowing us to add further features to the model. We will also discuss how accounting systems must generate performance measures, and how these measures can be used to design optimal contracts. Then, we discuss the role of comparability for relative performance evaluation and the role of disclosure of verifiable private information in the context of moral hazard. Lastly, we will discuss how the timeliness of accounting information can be used to design dynamic incentive contracts.\nThe notes borrow heavily from Lambert (2001), Bolton and Dewatripont (2005), and the PhD material elaborated by Jeremy Bertomeu and Edwige Cheynel, available from their websites.\n\n\nLet’s assume that a company (principal) hires a manager (agent) responsible for running the business. The company’s outcomes depend on both random factors and the manager’s effort. For now, let’s assume the effort can be either high (A) or low (B), and the company’s outcomes can either be success (E) or failure (F). The company’s profit in the success scenario is $360, and in the failure scenario, it is $200. The probability of success is 75% with high effort and 25% with low effort.\nTherefore, the expected profit of the principal when effort is high is: 360 \\times 0.75 + 200 \\times 0.25 = 320. In contrast, when the effort is low the expected profit is: 360 \\times 0.25 + 200 \\times 0.75 = 240.\nThis can be summarized in the following table:\n\n\n\n\nHigh Effort (A)\nLow Effort (B)\n\n\n\n\nSuccess (S)\n75%\n25%\n\n\nFailure (F)\n25%\n75%\n\n\nExpected Profit\n$320\n$240\n\n\n\nWe assume that the principal seeks to maximize the expected value of their net profits (expected value minus the payment to the agent). For now, let’s consider the principal to be risk-neutral.\nThe agent (manager) aims to maximize an expected utility function of the form:\n\nU = U(w) - v(e)\n\nWhere U(w) is the utility of the payment received (remuneration), and v(e) is the cost of effort e.\nWe can distinguish four possible cases:\n\nObservable effort, risk-neutral agent\nNon-observable effort, risk-neutral agent\nObservable effort, risk-averse agent\nNon-observable effort, risk-averse agent\n\n\n\nLet’s assume an agent with a utility function U = w - v(e), and a reservation utility of \\underline{U} = 81. The costs of effort are v(B) = 0 and v(A) = 63. (The numbers are arbitrary and chosen to facilitate later comparisons).\nIf the principal settles for low effort, they offer the agent a salary equal to the reservation utility w = 81. The expected profit for the principal is 240, and the net benefit is 240 - 81 = 159.\nIf the principal wants to ensure high effort, the agent’s remuneration must cover the disutility of effort, i.e., w = 81 + 63 = 144. The net profit for the principal in this case is 320 - 144 = 176.\nThus, for the principal, the best alternative is to offer a fixed payment of 144 and obtain an expected profit of 176.\n\n\n\nNow, consider the case where the effort (A or B) is non-observable and the agent continue being risk-neutral. In this case, the conflict between incentives and risk distribution is easily resolved. The most effective way to provide incentives is to make the agent bear all the consequences of their decisions.\nThe contract cannot depend on effort because effort is neither observable nor verifiable. However, results such as profits are observable. Therefore, the principal can exploit the correlation between effort and profits to incentivize the agent. The principal will pay X in case of success ($E$), and Y in case of failure (F). This introduces uncertainty for the agent.\nThe principal can induce high effort by offering the agent a contract characterized by a compensation conditional on the outcome: W_E and W_F, with the following requirements:\n\nIndividual Rationality: The utility for the agent must be greater than their reservation utility.\nIncentive Compatibility: The utility of exerting high effort must be greater than the utility of low effort, i.e.,E[U(A)] &gt; E[U(B)].\n\nIn our example, the constraints are:\n\n0.75 W_E + 0.25 W_F - 63 \\geq 81\n \n0.75 W_E + 0.25 W_F - 63 \\geq 0.25 W_E + 0.75 W_F\n\nAs it is inefficient for the principal to pay more than needed to influence effort, the previous system of inequations are solved at the equality conditions. The optimal contract in this case involves:\n\nW_E = 184, \\quad W_F = 24.\n\n\n\n\nQhat happens when we have a risk-averse agent? For example, assume the utility function U = W^{1/2} - v(e), where v(A) = 3 and v(B) = 0, and the reservation utility is \\underline{U} = 9.\nTo induce low effort, it is sufficient to offer a fixed salary that yields a utility level equal to or greater than the reservation utility (W=\\underline{U}^2=81). The principal’s expected net profit is 240 - 81 = 159, the same as in the scenario with a risk-neutral agent.\nTo induce high effort, the agent needs to be compensated for the additional disutility of the high effort. As effort can be observed, this can be achieved with a fixed salary of 144=(\\underline{U}+3)^2, conditioned on high effort . Thus, the expected net profit for the principal is 320 - 144 = 176, higher than the profit for low effort (though it may not always be optimal to pay for high effort).\nIn this case, the agent’s risk aversion does not pose a problem since there is no uncertainty involved. The agent’s action and payment are not contingent on the state of nature.1\n\n\n\nThe lack of observability of effort forces to create the compensation contract contingent on outcomes (which are correlated with effort) or abandoning variable compensation altogether. In this scenario we can see the main conflict in moral hazard problems:\n\nEfficient Risk Distribution: the risk-neutral party (the principal) should bear all the risk, while the risk-averse party (the agent) remains on the certainty line.\nIncentive Problem: For proper incentives, the agent must perceive differences in remuneration based on their effort level.\n\nThe challenge is to find the optimal balance between incentive provision and risk distribution. In the case of a risk-neutral agent, this was not a significant issue, as simply transferring residual control to the agent solved the problem. However, in this case, any variable compensation scheme must compensate the risk-averse agent for the risk they bear.\nFor comparison, let’s keep the utility function and parameters from the previous section. If the principal desires low effort, a fixed salary of 81 is sufficient. However, to incentive high effort, the contract with w = 144 will no longer suffice because effort is not observable, and uniform wages provide an incentive to cheat by exerting low effort.\nThe contract that induces high effort must meet both the individual rationality and incentive compatibility constraints, expressed as:\n\n0.75U(W_E) + 0.25U(W_F) - 3 \\geq 9\n\n\n0.75U(W_E) + 0.25U(W_F) - 3 \\geq 0.25U(W_E) + 0.75U(W_F)\n\nThe second constraint can be written as 0.5[U(W_E) - U(W_F)] \\geq 3. This captures the difference in utilities associated with the remuneration in each state, ensuring that high effort is chosen over low effort. The solution for this system of equation is W_E = 182.25 and W_F = 56.25. The expected cost of the contract that incentives high effor for the principal is 0.75 \\times 182.25 + 0.25 \\times 56.25 = 159.75, leaving them with an expected net benefit of 320 - 159.75 = 169.25.\nIt is important to note that inducing high effort now has a higher cost for the principal compared to the observable effort case. The cost has increased from 144 to 159.75. The additional 6.75 is the cost of non-observability, which economically corresponds to compensating the agent for the risk assumed."
  },
  {
    "objectID": "mora_hazard.html#a-very-simple-example",
    "href": "mora_hazard.html#a-very-simple-example",
    "title": "Contract Theory and Accounting",
    "section": "",
    "text": "Let’s assume that a company (principal) hires a manager (agent) responsible for running the business. The company’s outcomes depend on both random factors and the manager’s effort. For now, let’s assume the effort can be either high (A) or low (B), and the company’s outcomes can either be success (E) or failure (F). The company’s profit in the success scenario is $360, and in the failure scenario, it is $200. The probability of success is 75% with high effort and 25% with low effort.\nTherefore, the expected profit of the principal when effort is high is: 360 \\times 0.75 + 200 \\times 0.25 = 320. In contrast, when the effort is low the expected profit is: 360 \\times 0.25 + 200 \\times 0.75 = 240.\nThis can be summarized in the following table:\n\n\n\n\nHigh Effort (A)\nLow Effort (B)\n\n\n\n\nSuccess (S)\n75%\n25%\n\n\nFailure (F)\n25%\n75%\n\n\nExpected Profit\n$320\n$240\n\n\n\nWe assume that the principal seeks to maximize the expected value of their net profits (expected value minus the payment to the agent). For now, let’s consider the principal to be risk-neutral.\nThe agent (manager) aims to maximize an expected utility function of the form:\n\nU = U(w) - v(e)\n\nWhere U(w) is the utility of the payment received (remuneration), and v(e) is the cost of effort e.\nWe can distinguish four possible cases:\n\nObservable effort, risk-neutral agent\nNon-observable effort, risk-neutral agent\nObservable effort, risk-averse agent\nNon-observable effort, risk-averse agent\n\n\n\nLet’s assume an agent with a utility function U = w - v(e), and a reservation utility of \\underline{U} = 81. The costs of effort are v(B) = 0 and v(A) = 63. (The numbers are arbitrary and chosen to facilitate later comparisons).\nIf the principal settles for low effort, they offer the agent a salary equal to the reservation utility w = 81. The expected profit for the principal is 240, and the net benefit is 240 - 81 = 159.\nIf the principal wants to ensure high effort, the agent’s remuneration must cover the disutility of effort, i.e., w = 81 + 63 = 144. The net profit for the principal in this case is 320 - 144 = 176.\nThus, for the principal, the best alternative is to offer a fixed payment of 144 and obtain an expected profit of 176.\n\n\n\nNow, consider the case where the effort (A or B) is non-observable and the agent continue being risk-neutral. In this case, the conflict between incentives and risk distribution is easily resolved. The most effective way to provide incentives is to make the agent bear all the consequences of their decisions.\nThe contract cannot depend on effort because effort is neither observable nor verifiable. However, results such as profits are observable. Therefore, the principal can exploit the correlation between effort and profits to incentivize the agent. The principal will pay X in case of success ($E$), and Y in case of failure (F). This introduces uncertainty for the agent.\nThe principal can induce high effort by offering the agent a contract characterized by a compensation conditional on the outcome: W_E and W_F, with the following requirements:\n\nIndividual Rationality: The utility for the agent must be greater than their reservation utility.\nIncentive Compatibility: The utility of exerting high effort must be greater than the utility of low effort, i.e.,E[U(A)] &gt; E[U(B)].\n\nIn our example, the constraints are:\n\n0.75 W_E + 0.25 W_F - 63 \\geq 81\n \n0.75 W_E + 0.25 W_F - 63 \\geq 0.25 W_E + 0.75 W_F\n\nAs it is inefficient for the principal to pay more than needed to influence effort, the previous system of inequations are solved at the equality conditions. The optimal contract in this case involves:\n\nW_E = 184, \\quad W_F = 24.\n\n\n\n\nQhat happens when we have a risk-averse agent? For example, assume the utility function U = W^{1/2} - v(e), where v(A) = 3 and v(B) = 0, and the reservation utility is \\underline{U} = 9.\nTo induce low effort, it is sufficient to offer a fixed salary that yields a utility level equal to or greater than the reservation utility (W=\\underline{U}^2=81). The principal’s expected net profit is 240 - 81 = 159, the same as in the scenario with a risk-neutral agent.\nTo induce high effort, the agent needs to be compensated for the additional disutility of the high effort. As effort can be observed, this can be achieved with a fixed salary of 144=(\\underline{U}+3)^2, conditioned on high effort . Thus, the expected net profit for the principal is 320 - 144 = 176, higher than the profit for low effort (though it may not always be optimal to pay for high effort).\nIn this case, the agent’s risk aversion does not pose a problem since there is no uncertainty involved. The agent’s action and payment are not contingent on the state of nature.1\n\n\n\nThe lack of observability of effort forces to create the compensation contract contingent on outcomes (which are correlated with effort) or abandoning variable compensation altogether. In this scenario we can see the main conflict in moral hazard problems:\n\nEfficient Risk Distribution: the risk-neutral party (the principal) should bear all the risk, while the risk-averse party (the agent) remains on the certainty line.\nIncentive Problem: For proper incentives, the agent must perceive differences in remuneration based on their effort level.\n\nThe challenge is to find the optimal balance between incentive provision and risk distribution. In the case of a risk-neutral agent, this was not a significant issue, as simply transferring residual control to the agent solved the problem. However, in this case, any variable compensation scheme must compensate the risk-averse agent for the risk they bear.\nFor comparison, let’s keep the utility function and parameters from the previous section. If the principal desires low effort, a fixed salary of 81 is sufficient. However, to incentive high effort, the contract with w = 144 will no longer suffice because effort is not observable, and uniform wages provide an incentive to cheat by exerting low effort.\nThe contract that induces high effort must meet both the individual rationality and incentive compatibility constraints, expressed as:\n\n0.75U(W_E) + 0.25U(W_F) - 3 \\geq 9\n\n\n0.75U(W_E) + 0.25U(W_F) - 3 \\geq 0.25U(W_E) + 0.75U(W_F)\n\nThe second constraint can be written as 0.5[U(W_E) - U(W_F)] \\geq 3. This captures the difference in utilities associated with the remuneration in each state, ensuring that high effort is chosen over low effort. The solution for this system of equation is W_E = 182.25 and W_F = 56.25. The expected cost of the contract that incentives high effor for the principal is 0.75 \\times 182.25 + 0.25 \\times 56.25 = 159.75, leaving them with an expected net benefit of 320 - 159.75 = 169.25.\nIt is important to note that inducing high effort now has a higher cost for the principal compared to the observable effort case. The cost has increased from 144 to 159.75. The additional 6.75 is the cost of non-observability, which economically corresponds to compensating the agent for the risk assumed."
  },
  {
    "objectID": "mora_hazard.html#first-order-simplification",
    "href": "mora_hazard.html#first-order-simplification",
    "title": "Contract Theory and Accounting",
    "section": "First-order simplification",
    "text": "First-order simplification\nThe constraint in Equation 1 is not very tractable, and theorist have develop conditions where it can be replaced by the agent’s first-order condition on effort. If we assume that the agent’s optimal effort is in the interior of the effort set, then the agent first-order condition is\n\n\\sum_{i=1}^n p_i'(e)U(w(x_i)) - v'(e)=0\n\nThe issue with this method is that the first-order condition is necessary but not sufficient. Effort is present in both the disutility function v(e) and the probability distribution of results, implying that the expected utility function is not necessarily concave. Therefore, the first-order approach may yield more solutions than the original problem, potentially leading to suboptimal outcomes for the principal. We must impose restrictions on the conditional distribution of outcomes given effort to ensure that the second-order condition holds."
  },
  {
    "objectID": "mora_hazard.html#solving-the-optimal-contract",
    "href": "mora_hazard.html#solving-the-optimal-contract",
    "title": "Contract Theory and Accounting",
    "section": "Solving the optimal contract",
    "text": "Solving the optimal contract\nThe Lagrangian for the principal’s problem using the first-condition approach is:\n\nL(w(x),e) = \\sum_{i=1}^n p_i(e)[B(x_i - w(x_i))]+ \\lambda \\left[ \\sum_{i=1}^n p_i(e)U(w(x_i)) - v(e) -\\underline{U}  \\right] + \\mu \\left[\\sum_{i=1}^n p_i'(e)U(w(x_i)) - v'(e)\\right]\n\nwe can characterize the optimal contract by deriving the Lagrangian with respect to w for each value of x. This contract must satisfy that\n\n\\frac{B'(x_i - w(x_i))}{U'(w(x_i)) }= \\lambda + \\mu \\frac{p_i'(e)}{p_i(e)}\n\\tag{2}\nSo, \\mu=0 reduces the optimal contract to the first-best solution. Holmström (1979) shows that as long as the principal aims to influence more effort than the lowest possible, then \\mu&gt;0. In those cases, the optimal risk sharing depends on the sign and magnitude of \\frac{p_i'(e)}{p_i(e)}. An statistical interpretation of this ratio is that the principal use the outcome x to infer the parameter e, that is, the effort level taken (Milgrom 1981). In other words, the principal rewards the outcomes that are more likely to happen with higher level of efforts (p_i'(e)&gt;0).\nEquation 2 indicates that the optimal contract shape depends on the functional form for the principal’s and agent’s utility functions as well as for outcome distribution function. Depending on these settings, the optimal contract can be linear, convex, or concave in x. A sufficient condition for the contract to be monotonically increasing in the outcome is that \\frac{p_i'(e)}{p_i(e)}is increasing in the outcome (called monotone likelihood ratio condition, MLRC ), which is a stronger condition the the mean of the outcome distribution to increase with the outcome. This condition is meet by many common probability functions.\n\n\n\n\n\n\nLinearity in the Outcome\n\n\n\nEven if the likelihood ratio is monotonic and linear in the outcome, this would not imply that the optimal compensation is also linear in the outcome. As Equation 2 shows, the shape of the contract also depends on the preference functions of the agent and the principal.\n\n\nFor example, assuming the the principal is risk neutral and the agent’s has an hyperbolic absolute risk aversion (HARA) utility function, then the optimal compensation is a concave function of the outcome, as shown in Equation 3.\n\n\\begin{align*}\nU(x) &=\\frac{1}{1-\\gamma}\\left(\\delta_0+\\delta_1 x\\right)^{(1-\\gamma)}\\\\\nw^*(x) &= -\\frac{ \\delta_0}{ \\delta_1 x} + \\delta_1^{(1-\\gamma)/\\gamma} \\left[ \\lambda + \\mu \\frac{p_i'(e)}{p_i(e)} \\right]^{1/\\gamma}\n\\end{align*}\n\\tag{3}\nThus, the optimal contract is linear in the outcome if \\gamma=1 (e.g., logarithmic utility function), and concave (convex) if \\gamma&gt;1 (\\gamma&lt;1).\n\n\n\n\n\n\nLimited Liability\n\n\n\nIn many instances, the optimal compensation needs to be bounded below given limited liability or wealth constraints of the agent. The problem is that Equation 2 implies penalization to the agent for bad outcomes. Therefore, the optimal compensation is often nondifferentiable and has a piecewise linear form. See Mirrlees (1974)."
  },
  {
    "objectID": "mora_hazard.html#accounting-performance-measures",
    "href": "mora_hazard.html#accounting-performance-measures",
    "title": "Contract Theory and Accounting",
    "section": "Accounting performance measures",
    "text": "Accounting performance measures\nNow let’s add an additional performance measure to the model to check in which conditions they reduced the welfare loss relative to the first-best solution. This will be the case if they increase the agent’s incentive to exert effort or improve the risk-sharing between the principal and the agent. Be y the performance measure. In this case, Equation 2 becomes\n\n\\frac{B'(x_i - w(x_i,y_i))}{U'(w(x_i,y_i)) }= \\lambda + \\mu \\frac{p_i'(x,y;e)}{p_i(x,y;e)}\n\\tag{4}\nThus, the optimal contract depends on the performance metric if \\frac{p_i'(x,y;e)}{p_i(x,y;e)} also depends on y. However, if x is a sufficient statistic for x and y with respect to e, then the optimal contract is independent of y. This is called Holmstrom’s informativeness condition (Holmström 1979).\n\n\n\n\n\n\nSufficient Statistic\n\n\n\nIf x=e+a_1 and y=x+a_2, where a_1 and a_2 are independent random variables, then x is a sufficient statistic for x and y with respect to e. In other words, y does not add any information about e that is not already contained in x.\n\n\nAccounting systems aggregate performance measures. The demand for aggregation of performance measures arises because reporting all the basic transactions and other nonfinancial information is costly and unrealistic. Accountants aggregate linearly these measures assigning equal weights to each them. For example, total cost is the sum of each cost item, net benefits is revenues minus expenses. Furthermore, in practice, performance evaluation and compensation usually rely on those accounting aggregated metrics. To what extent contract theory support the linear aggregation of performance with equal weights? Banker and Datar (1989) provide theoretical support for the linear aggregation but also highlight that the equal weights assumption is rarely optimal. The components of the performance measure should be weighted according to agent’s capacity to influence them and their noisiness. Thus, only in cases where the signal-to-noise ratio is the same for all components, the equal weights assumption might be optimal. To see this, let’s continue with the same example but now assume that the principal is risk neutral and that x and y are both performance metrics. The optimal contract is given by Equation 4 and yields\n\nw^*(x,y)= W \\left[ \\lambda + \\mu \\frac{p_i'(x,y;e)}{p_i(x,y;e)} \\right]\n\nwhere W is the inverse of the agent’s marginal utility function. Let’s define a new compensation function s(\\phi) which depends on the aggregate performance measure \\pi=\\pi(x,y)=\\lambda + \\mu \\frac{p_i'(x,y;e)}{p_i(x,y;e)}. For many probability distributions, such as those in the exponential family, the likelihood ratio is linear in x and y, thus the optimal contract supports linear aggregation. In terms of the optimal weights, Banker and Datar (1989) shows that for the exponential family of distribution, when both metrics are independently distributed given the agent’s effort, then the optimal weights are proportional to (1) the sensitivity of the metric to the effort, and (2) to the inverse of the variance of the performance metrics. If we denote the weights as \\beta_x and \\beta_y, then the optimal weights are given by\n\n\\beta_x  = \\frac{\\frac{\\partial E(x;e)}{ \\partial e} var(y) }{ \\left[ var(x)+var(y) \\right]}\n\\tag{5}\nand \n\\beta_y  = \\frac{\\frac{\\partial E(y;e)}{ \\partial e} var(x) }{ \\left[ var(x)+var(y) \\right]}\n\nand the relative weights are\n\n\\frac{\\beta_x}{\\beta_y} = \\frac{\\partial E(x;e)/ \\partial e}{var(x)} \\frac{var(y)}{\\partial E(y;e)/ \\partial e}\n\\tag{6}\n\n\n\n\n\n\nThe relevance of variables not controlled by the agent\n\n\n\nIf the principal or other agent invest in technology or capital such as the agent’s effort is more productive or the performance metric is more sensitive to its effort, then it is optimal to introduce those variables into the contract even though are not controlled by the agent. In this case, the optimal contract adjusts the compensation to subtract the principal’s investment effect on the mean outcome or adjusts the weights of the performance metrics to reflect their new informativeness.\n\n\nHow the optimal contract should weights performance metrics that are correlated? In that case, Equation 6 is rewritten as\n\n\\frac{\\beta_x}{\\beta_y} = \\frac{ \\frac{\\partial E(x;e)}{\\partial e} - \\frac{cov(x,y)}{var(y)}\\frac{\\partial E(y;e)}{\\partial e} }{var(x)} \\frac{var(y)}{\\frac{\\partial E(y;e)}{\\partial e} - \\frac{cov(x,y)}{var(x)}\\frac{\\partial E(x;e)}{\\partial e}}\n\\tag{7}\nso, even if the agent does not control y (e.g., \\frac{\\partial E(y;e)}{\\partial e}=0) then both metrics should be included in the contract with weights that reflect the correlation between them.\n\n\\frac{\\beta_x}{\\beta_y} = -\\frac{var(y)}{covar(x,y)}\n\nThus, if the metrics are positively correlated, then their weights have opposite signs. The interpretation is that the positive correlation is driven by an exogenous common factor, and by adjusting y with a negative weight some of the noise driven by the common factor in x is removed."
  },
  {
    "objectID": "mora_hazard.html#solving-the-optimal-contract-1",
    "href": "mora_hazard.html#solving-the-optimal-contract-1",
    "title": "Contract Theory and Accounting",
    "section": "Solving the optimal contract",
    "text": "Solving the optimal contract\nAs \\mathbb{E}\\left[e^{k\\epsilon}\\right]=e^{k^{2}\\frac{\\sigma^{2}}{2}} for any k, the expected agent’s utility is\n \\mathbb{E}\\left[u(w,e)\\right] =-e^{-\\eta\\left[t+se-\\frac{1}{2}ce^{2}-s^{2}\\eta\\frac{\\sigma^{2}}{2}\\right]}.\nNow we can reformulate the agent’s problem as\n\ne \\in\\arg\\max\\hat{w}(e)=t+se-\\frac{1}{2}ce^{2}-s^{2}\\eta\\frac{\\sigma^{2}}{2}\n\nobtaining e^*=\\frac{s}{c}. So for any given performance incentive s, the principal knows the effort choice of the agent.\nIntroducing the optimal effort into the principal’s problem reduces the optimization variables (now depending only on the contract terms) and the number of restrictions. The principal’s problem is now\n\n\\underset{t,s}{\\max} \\ \\frac{s}{c}-t-s\\left(\\frac{s}{c}\\right)\n Subject to \nt+s\\left[\\frac{s}{c}\\right]-\\frac{1}{2}c\\left[\\frac{s}{c}\\right]^{2}-s^{2}\\eta\\frac{\\sigma^{2}}{2}= \\overline{w}\n\nBy solving the principal’s problem, we obtain the optimal compensation terms:\n\n\\begin{align*}\ns^{*} &= \\frac{1}{\\left[1+c\\eta\\sigma^{2}\\right]}\\\\\nt^{*} &= \\overline{w}-\\frac{1-c\\eta\\sigma^{2}}{2c\\left[1+c\\eta\\sigma^{2}\\right]^{2}}\n\\end{align*}\n\nso the variable compensation is high when the cost of effort c is low, the degree of risk aversion \\eta is low, and randomness of the output \\sigma is low.\n\n\nCode\nimport matplotlib.pyplot as plt\nimport numpy as np\nc=0.8 # cost of effort\neta=1.5 # risk aversion\nw=1     # reservation utility\n# Plot s,t,and total, for different values of sigma \nsigma = np.linspace(0,2,10)\ns = 1/(1+c*eta*sigma**2)\nt = w - (1-c*eta*sigma**2)/(2*c*(1+c*eta*sigma**2)**2) \ntotal = t + s \neffort = s/c \nplt.plot(sigma, s, label='s')\nplt.plot(sigma, t, label='t')\nplt.plot(sigma, total, label='total')\nplt.plot(sigma, effort, label='effort', linestyle='dashed')\nplt.legend()\n# render sigma symbol in the x label\nplt.xlabel('Value of $\\sigma$')\nplt.ylabel('Value')\nplt.title('Optimal contract terms')\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nCode\n# plot the utility of the agent and principal for different values of sigma\nu_agent = -np.exp(-eta*(t+s*effort-0.5*c*effort**2-s**2*eta*sigma**2/2)) \nu_principal = effort-t-s*effort\nplt.plot(sigma, u_agent, label='Agent')\nplt.plot(sigma, u_principal, label='Principal')\nplt.legend()\nplt.xlabel('Value of $\\sigma$')\nplt.ylabel('Utility')\nplt.title('Agent and Principal utility')\nplt.show()"
  },
  {
    "objectID": "mora_hazard.html#accounting-perfomance-measures",
    "href": "mora_hazard.html#accounting-perfomance-measures",
    "title": "Contract Theory and Accounting",
    "section": "Accounting perfomance measures",
    "text": "Accounting perfomance measures\nLet’s again assume again that x and y are both accounting signals, such as x=e+\\epsilon_x and y=2e+\\epsilon_y, where \\epsilon_x and \\epsilon_y are joinly normally distributed with zero means. Then, the joint distribution function f(x,y;e) is a bivariate normal distribution with\n\nMean vector: \n\\mu_{x,y} = \\left(\\begin{array}{c} e \\\\ 2e \\end{array}\\right)\n\nCovariance matrix: \n\\Sigma_{x,y} = \\left(\\begin{array}{cc} \\sigma_x^2 & \\rho \\sigma_x \\sigma_y \\\\ \\rho \\sigma_x \\sigma_y & \\sigma_y^2 \\end{array}\\right)\n\n\nwhere \\sigma_x^2 is the variance of \\epsilon_x, \\sigma_y^2 is the variance of \\epsilon_y, and \\rho is the correlation coefficient between \\epsilon_x and \\epsilon_y. The accounting system aggregates both signals into a single performance measure \\pi=\\pi(x,y). The Equation 7 becomes\n\n\\frac{\\beta_x}{\\beta_y} = \\frac{1-2\\frac{\\rho \\sigma_x \\sigma_y}{\\sigma_y^2}}{\\sigma_x^2}\\frac{\\sigma_y^2}{2-\\frac{\\rho \\sigma_x \\sigma_y}{\\sigma_x^2}}\n\nLet’s see the comparative statics of the optimal weights for different values of \\rho and \\sigma_y. First, let’s assume that both signals have the same noise, \\sigma_x=\\sigma_y=2.5.\n\n\nCode\n# plot the beta_x/beta_y for different values of rho \nrho = np.linspace(-1,1,20)\nsigma_y = 2.5\nsigma_x = 2.5\n# subplot for rho\nbeta_rho = (1-2*(rho*sigma_x*sigma_y)/(sigma_y)**2)/(sigma_x**2)*(sigma_y**2)/(2-(rho*sigma_x*sigma_y)/(sigma_x)**2)\nplt.plot(rho, beta_rho)\nplt.xlabel('correlation coefficient')\n# add vertical line in x=0\nplt.axvline(x=0, color='r', linestyle='--')\n## add subtitle\nplt.title('Relative Optimal Weights')\nplt.show()\n\n\n\n\n\n\n\n\n\nso, if \\rho=0, the optimal contract weight for x is half of the weight for y, as this second signal is more sensitive to effort and has the same noise. If \\rho=-1, then both both signal have full positive weight in the contract. If \\rho=1, then the signals are substracted from each other in the contract to remove the common noise.\nNow, let’s see the comparative statics for different values of \\sigma_y, considering \\rho=0 and \\sigma_x=2.5.\n\n\nCode\n# plot the beta_x/beta_y for different values of sigma_y\nrho=0\nsigma_y = np.linspace(0.1,5,10)\nsigma_x = 2.5\n# plot for sigma_y\nbeta_sigma_y = (1-2*(rho*sigma_x*sigma_y)/(sigma_y)**2)/(sigma_x**2)*(sigma_y**2)/(2-(rho*sigma_x*sigma_y)/(sigma_x)**2)\nplt.axvline(x=2.5, color='r', linestyle='--')\nplt.plot(sigma_y, beta_sigma_y)\nplt.xlabel('Value of $\\sigma_y$')\nplt.title('Relative Optimal Weights')\nplt.show()\n\n\n\n\n\n\n\n\n\nHere the red line despicts the same situation than in the previous plot, meaning that when both signals have the same noise. The optimal weight for x is half of the weight for y. If \\sigma_y gets closer to zero, then the weight for x decreases as y gets a better relative signal-to-noise ratio."
  },
  {
    "objectID": "mora_hazard.html#optimal-contract-with-performance-measures",
    "href": "mora_hazard.html#optimal-contract-with-performance-measures",
    "title": "Contract Theory and Accounting",
    "section": "Optimal contract with performance measures",
    "text": "Optimal contract with performance measures\nTo evaluate how the optimal contract changes with the use of the aggregate performance metric we should compute the aggregated signal \\pi(x,y)=\\beta_x x+ \\beta_y y using Equation 5 and x and y as defined in the previous section with \\rho=0.\n\n\\pi(x,y)=\\frac{\\sigma_y^2}{\\sigma_x^2+\\sigma_y^2} x+ 2 \\frac{\\sigma_x^2}{\\sigma_x^2+\\sigma_y^2} y\n\nNow, the compensation functions depens on the aggregated signal \\pi (rather than on the output x), meaning that now w(\\pi)=t+s\\pi. Notice that \\pi \\sim N(\\mu_{\\pi},\\sigma_{\\pi}^2), with\n\n\\begin{align}\n\\mu_{\\pi}(e) &= \\frac{e}{\\sigma_x^2+\\sigma_y^2} \\left[  \\sigma_y^2+4\\sigma_x^2 \\right]\\\\\n\\sigma_{\\pi}^2(e) &= \\frac{\\sigma_x^2\\sigma_y^2}{(\\sigma_x^2+\\sigma_y^2)^2}\\left[  \\sigma_y^2+4\\sigma_x^2 \\right]\n\\end{align}\n\nWe can reformulate agent’s problem as \ne \\in\\arg\\max\\hat{w}(e)=t+s\\mu_{\\pi}-\\frac{1}{2}ce^{2}-s^{2}\\eta\\frac{\\sigma_{\\pi}^2 }{2}\n\nobtaining optimal effort equals to \ne^*=\\frac{s}{c} \\left[\\frac{\\sigma_y^2+4\\sigma_x^2}{\\sigma_x^2+\\sigma_y^2} \\right]\n\\tag{8}\nRelative to our initial result (e^*=s/c), Equation 8 shows that having the aggregated metric \\pi in the contract increases the optimal effort level. This is because the aggregated metric is more sensitive to the agent’s effort than the individual signals. The updated principal’s problem is \n\\underset{t,s}{\\max} \\ \\mu_{\\pi}(e^*)-t-s\\mu_{\\pi}(e^*)\n Subject to \nt+s[e^*]-\\frac{1}{2}c[e^*]^{2}-s^{2}\\eta\\frac{\\sigma_{\\pi}^2(e^*)}{2}= \\overline{w}"
  },
  {
    "objectID": "mora_hazard.html#recent-papers-in-accounting",
    "href": "mora_hazard.html#recent-papers-in-accounting",
    "title": "Contract Theory and Accounting",
    "section": "Recent papers in Accounting",
    "text": "Recent papers in Accounting\n\nEarnings vs. stock-price based incentives in managerial compensation contracts\nDynamic performance measurement with intangible assets\nDynamic performance measurement\nTimeliness, Accuracy, and Relevance in Dynamic Incentive Contracts"
  },
  {
    "objectID": "mora_hazard.html#footnotes",
    "href": "mora_hazard.html#footnotes",
    "title": "Contract Theory and Accounting",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nAdditionally, if the agent has bargaining power, they could negotiate up to 161 for high effort. Analyse the Edgeworth box representation.↩︎"
  }
]